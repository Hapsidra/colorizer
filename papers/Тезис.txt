Здравстуйте меня зовут Ефимов Максим, тема моей работы называется "Разработка приложения для раскраски черно-белых изображений методами машинного обучения".

Основными задачами в этой работе является: изучение алгоритмов глубоко обучения, создание модели для раскраски изображений, 
конвертация этой модели в CoreML и разработка приложения под айос на основе этой модели

Раскраска вручную черно-белых фотографий например в программе фотошоп занимает много времени и сил.
Притом большинство фотографий и документов, таких как книги, газеты, манги и т. п. ради дешевизны по сей день печатаются в черно-белом варианте.   
Задачу раскраски черно-белых изображений можно автоматизировать с помощью приложения на основе нейронных сетей.

Существуют решения, такие как Algorithmia и DeOldify, но они обладают своими нюансами.
Algorithmia - это алгоритм разработанный Ричардом Чжаном в 2016 году. 
Модель представляет из себя feed-forward CNN и тренирована на более чем миллионе фотографий ImageNet. 
Реализовано на устаревшем на данный момент фреймворке caffe. 
Модель использует цветовую модель CIELab. В качестве входа используется L канал, а в качестве выхода каналы a и b. 
Минус такого подхода в том что сложно использовать предобученные модели, потому что они, как правило, обучаются с использованием цветовой модель RGB. 
DeOldify
Модель глубокого обучения с использованием архитектуры GAN. Генеративная модель – это предобученная на imagenet модель U-Net. 
Функция потерь состоит из двух частей. Первая это Perceptual Loss (Feature Loss) основанная на VGG16. 
Вторая это функция потерь дискриминационной модели. Реализована с использованием фреймворка Fast.AI. 
Модель является весьма требовательным к ресурсам поэтому его нельзя запустить на телефоне без сильной оптимизации. 
Плюс к этому у фреймворка Fast.AI слабая поддержка конвертиции в CoreML. 
По сути ее нет потому что сперва эту модель надо сконверитовать в одну из моделей которая поддерживается CoreML и только потом из нее сконверитровать в CoreML.
Как вывод можно сказать что Algorithmia работает не очень хорошо и учитывая сложности конвертации модели DeOldify было решено переписать его оптимизированную 
под телефоны версию с использование популярного фреймворка Keras, потому что у него хорошая поддержка конвертации в CoreML.

сравнения

Модель является глубокой нейронной сетью GAN где генеративная модель это U-Net. 
Датасет составляется из пар цветных изображений с его черно-белой версией. Данные нормализуются в диапазоне от -1 до 1

GAN или Генеративно-состязательная сеть – это класс моделей машинного обучения без учителя, 
в котором используется две нейронных сети, одна из которых генерирует новые объекты (генеративная модель), 
а другая старается отличить правильные объекты от неправильных (дискриминативная модель).
Дискриминативная модель – это стандартная сверточная сеть, которая классифицирует поданные на вход объекты. 
Генеративная модель – это обратная сверточная сеть, которая на основе случайного шума создает объект

U-Net — это свёрточная нейронная сеть, которая была создана в 2015 году для сегментации биомедицинских изображений в отделении Computer Science Фрайбургского университета.
Архитектура сети
Сеть содержит сжимающий путь (слева) и расширяющий путь (справа), поэтому архитектура похожа на букву U, что и отражено в названии.

Функция потерь это комбинация Feature Loss и потери дискриминатора.
Feature Loss – эта техника при которой вместо попиксельного сравнения картинок сравниваются высокоуровневые характеристики картинок. 
Для этого используется предобученная модель классификации из которой извлекается слой характеристик и генеративная модель старается восстановить эти характеристики. 
Характеристики представлены числами, минимизируется разница между ними, обычно используется среднеквадратическая ошибка. 
Предобученная модель во время обучения замораживается.

Дискриминатор получает на вход картинку и старается угадать класс картинки: настоящая или сгенерированная. 
Функция активации на выходном слое сигмоида и указывает на вероятность класса где 0 это сгенерированная картинка 1 настоящая. 
Функция потерь среднеквадратичная ошибка. 

Генератор это стандартный unet. Выходных слоев 3 соотвественно на каждый канал RGB. 
Функция активации на выходе тангенс потому что мы нормализовали наши данные в диапазоне от -1 до 1. 

GAN состоит из трех моделей: генератора, дискриминатора и VGG для feature loss. Сначала черно-белая картинка подается на вход генератору, а результат генератора имеет два пути: 
В первом случае она подается на вход дискриминатору который предсказывает класс картинки. Функция потерь здесь бинарная кросс энтропия. 
Второй путь это feature loss, из результата извлекаются характеристики. Функция потерь здесь среднеквадратичная ошибка.
Притом вес у функции потери feature loss больше, то есть модель будет учитывать его сильнее. Дискриминатор во время обучения GAN не обучается.

Запускать модель на телефоне вместо обработки картинок на сервере имеет много преимуществ. Основные из них:
Бесплатные вычисления. Аренда сервера, интернет трафик стоят денег, это особенно критично для бесплатных приложений.
Нет потенциальных проблем с безопасностью. При хранение и пересылки пользовательских данных всегда есть вероятность кражи, утери. 
При обработке данных на телефоне у Вас гарантированно нет такой проблемы.
Неограниченная масштабируемость. При большом количестве пользователей сервер может не справиться с нагрузкой.
CoreML – это фреймворк разработанный компанией Apple для интеграции моделей машинного обучение в телефоны операционной системы iOS.
Core ML Community Tools – это библиотека от сообщества для конвертации, редактирование и проверки моделей машинного обучения таких как TensorFlow, Keras, Caffe, scikit-learn и других.

Приложение написано на языке Swift в среде разработке Xcode.
В приложение можно загрузить любое черно-белое изображение из библиотеки и получить его раскрашенную с помощью модели версию, которую потом можно сохранить. 
Для запуска модели и предобработки изображений используется фреймворк Vision.
CoreML модель которая была получена в результате конвертация перетаскивается внутрь проекта Xcode. Классы необходимые для его работы генерируются автоматически CoreML

В заключении решенены следующие задачи
Создана модель раскраски
Модель сконвертирована в CoreML
Разработано приложение для раскраски
Приложение опубликовано в AppStore qr код это ссылка на аппстор

Ну и в конце посмотрим на демо приложения
