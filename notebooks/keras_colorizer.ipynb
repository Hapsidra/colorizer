{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "brKY4zEccKnZ"
   },
   "source": [
    "# Keras colorizer of CelebA using Generative Adversarial Networks.\n",
    "The dataset can be downloaded from: https://www.dropbox.com/sh/8oqt9vytwxb3s4r/AADIKlz8PR9zr6Y20qbkunrba/Img/img_align_celeba.zip?dl=0\n",
    "## Instrustion on running the script:\n",
    "1. Download the dataset from the provided link\n",
    "2. Save the folder 'img_align_celeba' to 'datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "hvSFlk6kVhko",
    "outputId": "74539bf7-76bc-4b9f-891b-6f82bed2d22c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wHjTCYzJNvFZ"
   },
   "outputs": [],
   "source": [
    "! mkdir datasets\n",
    "! mkdir originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gu8Jm-c8sMhe"
   },
   "outputs": [],
   "source": [
    "! unzip -q \"/content/drive/My Drive/img_align_celeba.zip\" -d datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0oNurEUNy6V"
   },
   "outputs": [],
   "source": [
    "! unzip -q \"/content/drive/My Drive/coco_val2017.zip\" -d datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Mkb1xGjOH6P"
   },
   "outputs": [],
   "source": [
    "! mv datasets/val2017/* originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5oX2UN5FQl40"
   },
   "outputs": [],
   "source": [
    "! find /content/datasets/img_align_celeba -type f -exec sh -c 'mv \"$@\" \"$0\"' originals/ {} +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting segmentation-models\n",
      "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
      "Collecting efficientnet==1.0.0\n",
      "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
      "Collecting image-classifiers==1.0.0\n",
      "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in d:\\anaconda3\\lib\\site-packages (from segmentation-models) (1.0.8)\n",
      "Requirement already satisfied: scikit-image in d:\\anaconda3\\lib\\site-packages (from efficientnet==1.0.0->segmentation-models) (0.16.2)\n",
      "Requirement already satisfied: h5py in d:\\anaconda3\\lib\\site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in d:\\anaconda3\\lib\\site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.19.0 in d:\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.1)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in d:\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.1.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.1.3)\n",
      "Requirement already satisfied: pillow>=4.3.0 in d:\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (7.0.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in d:\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.6.1)\n",
      "Requirement already satisfied: networkx>=2.0 in d:\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4)\n",
      "Requirement already satisfied: six in d:\\anaconda3\\lib\\site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.14.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in d:\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation-models) (4.4.1)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (45.2.0.post20200210)\n",
      "Installing collected packages: efficientnet, image-classifiers, segmentation-models\n",
      "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 segmentation-models-1.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install segmentation-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pjIUDN76FDeQ",
    "outputId": "9f1b8614-7bb2-4499-a1b3-34e534776517"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add, MaxPooling2D\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.applications import VGG19\n",
    "from keras.models import Sequential, Model\n",
    "import keras\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import keras.backend as K\n",
    "import scipy.misc\n",
    "import PIL\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.applications.vgg19 import preprocess_input as vgg19_preprocess_input\n",
    "from keras.optimizers import Adam\n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 3} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = sm.get_preprocessing('resnet34')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function classification_models.models.resnet.preprocess_input(x, **kwargs)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URIEcC5yHza8"
   },
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "  def __init__(self, img_res=(256, 256)):\n",
    "    self.img_res = img_res\n",
    "\n",
    "  def load_data(self, batch_size=1, is_testing=False):\n",
    "    path = glob('./originals/*')\n",
    "    batch_images = np.random.choice(path, size=batch_size)\n",
    "\n",
    "    imgs_hr = []\n",
    "    imgs_lr = []\n",
    "    for img_path in batch_images:\n",
    "      img_hr, img_lr = self._load(img_path, self.img_res)\n",
    "\n",
    "      imgs_hr.append(img_hr)\n",
    "      imgs_lr.append(img_lr)\n",
    "      \n",
    "    # нормализация данных\n",
    "    imgs_hr = np.array(imgs_hr) / 127.5 - 1\n",
    "    imgs_lr = np.array(imgs_lr) / 127.5 - 1\n",
    "\n",
    "    return imgs_hr, imgs_lr\n",
    "\n",
    "  # returns pair (original photo, grayscale photo)\n",
    "  def _load(self, path, size):\n",
    "    img = PIL.Image.open(path).resize(size).convert('RGB')\n",
    "    return np.array(img).astype(np.float), np.array(img.convert('L').convert('RGB')).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-MMu2-hCHgAJ"
   },
   "outputs": [],
   "source": [
    "hr_channels = 3\n",
    "lr_channels = 3\n",
    "width = 512\n",
    "lr_shape = (width, width, lr_channels)\n",
    "hr_shape = (width, width, hr_channels)\n",
    "\n",
    "n_residual_blocks = 16\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "# configure data loader\n",
    "data_loader = DataLoader(img_res=(width, width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kt5tos90ZI8e"
   },
   "outputs": [],
   "source": [
    "def sample_images(epoch):\n",
    "  os.makedirs('samples', exist_ok=True)\n",
    "  r,c = 2,3\n",
    "  imgs_hr, imgs_lr = data_loader.load_data(batch_size=2, is_testing=True)\n",
    "  fake_hr = generator.predict(imgs_lr)\n",
    "  imgs_lr = 0.5 * imgs_lr + 0.5\n",
    "  fake_hr = 0.5 * fake_hr + 0.5\n",
    "  imgs_hr = 0.5 * imgs_hr + 0.5\n",
    "  titles = [\"B&W\", \"Generated\", \"Original\"]\n",
    "  fig, axs = plt.subplots(r, c)\n",
    "  cnt = 0\n",
    "  for row in range(r):\n",
    "    for col, image in enumerate([imgs_lr, fake_hr, imgs_hr]):\n",
    "        axs[row, col].imshow(image[row])\n",
    "        axs[row, col].set_title(titles[col])\n",
    "        axs[row, col].axis('off')\n",
    "    cnt += 1\n",
    "  def zerofy(s: str):\n",
    "    while len(s) < 6:\n",
    "      s = '0' + s\n",
    "    return s\n",
    "  fig.savefig('samples/'+zerofy(str(epoch)) +'.png')\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oK8xkM2TT6v_"
   },
   "source": [
    "We use a pre-trained VGG19 model to extract image features from the high resolution and the generated high resolution images and minimize the mse between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eLR8rIHUT9eT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def build_feature_loss(input_size):\n",
    "  vgg = VGG19(weights='imagenet')\n",
    "  vgg.outputs = [vgg.layers[9].output]\n",
    "  img = Input(shape=input_size)\n",
    "  img_features = vgg(img)\n",
    "  model = Model(img, img_features)\n",
    "  model.trainable = False \n",
    "  model.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "  return model\n",
    "feature_loss = build_feature_loss(hr_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6wF4i0XbWxrn"
   },
   "source": [
    "build and compile the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yioy3rrNWwge"
   },
   "outputs": [],
   "source": [
    "def build_discriminator(input_size):\n",
    "  # Number of filters in the first layer of G and D\n",
    "  gf = 64\n",
    "  df = 64\n",
    "  def d_block(layer_input, filters, strides=1, bn=True):\n",
    "    \"\"\"Discriminator layer\"\"\"\n",
    "    d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    if bn:\n",
    "        d = BatchNormalization(momentum=0.8)(d)\n",
    "    return d\n",
    "\n",
    "  # Input img\n",
    "  d0 = Input(shape=input_size)\n",
    "\n",
    "  d1 = d_block(d0, df, bn=False)\n",
    "  d2 = d_block(d1, df, strides=2)\n",
    "  d3 = d_block(d2, df*2)\n",
    "  d4 = d_block(d3, df*2, strides=2)\n",
    "  d5 = d_block(d4, df*4)\n",
    "  d6 = d_block(d5, df*4, strides=2)\n",
    "  d7 = d_block(d6, df*8)\n",
    "  d8 = d_block(d7, df*8, strides=2)\n",
    "\n",
    "  d9 = Dense(df*16)(d8)\n",
    "  d10 = LeakyReLU(alpha=0.2)(d9)\n",
    "  validity = Dense(1, activation='sigmoid')(d10)\n",
    "\n",
    "  model = Model(d0, validity)\n",
    "  model.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "discriminator = build_discriminator(input_size=hr_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mfdNrMciXgu4"
   },
   "source": [
    "Build the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "a2IkeOr68P_L",
    "outputId": "abf8f15e-9e34-42b6-fef1-fbae41d6b440"
   },
   "outputs": [],
   "source": [
    "def unet(pretrained_weights = None, input_size = (256, 256, 3)):\n",
    "  inputs = Input(input_size)\n",
    "  conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "  conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "  conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "  conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "  conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "  conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "  conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "  conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "  drop4 = Dropout(0.5)(conv4)\n",
    "  pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "  conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "  conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "  drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "  up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "  merge6 = concatenate([drop4,up6], axis = 3)\n",
    "  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "  up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "  merge7 = concatenate([conv3,up7], axis = 3)\n",
    "  conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "  conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "  up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "  merge8 = concatenate([conv2,up8], axis = 3)\n",
    "  conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "  conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "  up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "  merge9 = concatenate([conv1,up9], axis = 3)\n",
    "  conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "  conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "  conv9 = Conv2D(3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "  conv10 = Conv2D(3, 1, activation = 'tanh')(conv9)\n",
    "\n",
    "  model = Model(input = inputs, output = conv10)\n",
    "  \n",
    "  #model.summary()\n",
    "\n",
    "  if(pretrained_weights):\n",
    "    model.load_weights(pretrained_weights)\n",
    "  model.compile(optimizer = Adam(lr = 1e-4), loss = 'mse', metrics = ['accuracy'])\n",
    "  return model\n",
    "#generator = unet(input_size=lr_shape)\n",
    "generator = sm.Unet('resnet34', input_shape=(width, width, 3), encoder_weights='imagenet', classes=3, activation=\"tanh\", encoder_freeze=True,decoder_filters=(1024, 512,256, 128, 64))\n",
    "generator.compile(optimizer = Adam(lr = 1e-4), loss = 'mse', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 512, 512, 3)  9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_35 (ZeroPadding2 (None, 518, 518, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 256, 256, 64) 9408        zero_padding2d_35[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 256, 256, 64) 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 256, 256, 64) 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_36 (ZeroPadding2 (None, 258, 258, 64) 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 128, 128, 64) 0           zero_padding2d_36[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 128, 128, 64) 256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 128, 128, 64) 0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_37 (ZeroPadding2 (None, 130, 130, 64) 0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 128, 128, 64) 36864       zero_padding2d_37[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 128, 128, 64) 256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 128, 128, 64) 0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_38 (ZeroPadding2 (None, 130, 130, 64) 0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 128, 128, 64) 36864       zero_padding2d_38[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 128, 128, 64) 4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 128, 128, 64) 0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 128, 128, 64) 256         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 128, 128, 64) 0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_39 (ZeroPadding2 (None, 130, 130, 64) 0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 128, 128, 64) 36864       zero_padding2d_39[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 128, 128, 64) 256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 128, 128, 64) 0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_40 (ZeroPadding2 (None, 130, 130, 64) 0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 128, 128, 64) 36864       zero_padding2d_40[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 128, 128, 64) 0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1 (BatchNormaliz (None, 128, 128, 64) 256         add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1 (Activation) (None, 128, 128, 64) 0           stage1_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_41 (ZeroPadding2 (None, 130, 130, 64) 0           stage1_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1 (Conv2D)     (None, 128, 128, 64) 36864       zero_padding2d_41[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2 (BatchNormaliz (None, 128, 128, 64) 256         stage1_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2 (Activation) (None, 128, 128, 64) 0           stage1_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_42 (ZeroPadding2 (None, 130, 130, 64) 0           stage1_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2 (Conv2D)     (None, 128, 128, 64) 36864       zero_padding2d_42[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 128, 128, 64) 0           stage1_unit3_conv2[0][0]         \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 128, 128, 64) 256         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 128, 128, 64) 0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_43 (ZeroPadding2 (None, 130, 130, 64) 0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 64, 64, 128)  73728       zero_padding2d_43[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 64, 64, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 64, 64, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_44 (ZeroPadding2 (None, 66, 66, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 64, 64, 128)  147456      zero_padding2d_44[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 64, 64, 128)  8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 64, 64, 128)  0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 64, 64, 128)  512         add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 64, 64, 128)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_45 (ZeroPadding2 (None, 66, 66, 128)  0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 64, 64, 128)  147456      zero_padding2d_45[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 64, 64, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 64, 64, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_46 (ZeroPadding2 (None, 66, 66, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 64, 64, 128)  147456      zero_padding2d_46[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 64, 64, 128)  0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1 (BatchNormaliz (None, 64, 64, 128)  512         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1 (Activation) (None, 64, 64, 128)  0           stage2_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_47 (ZeroPadding2 (None, 66, 66, 128)  0           stage2_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1 (Conv2D)     (None, 64, 64, 128)  147456      zero_padding2d_47[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2 (BatchNormaliz (None, 64, 64, 128)  512         stage2_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2 (Activation) (None, 64, 64, 128)  0           stage2_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_48 (ZeroPadding2 (None, 66, 66, 128)  0           stage2_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2 (Conv2D)     (None, 64, 64, 128)  147456      zero_padding2d_48[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 64, 64, 128)  0           stage2_unit3_conv2[0][0]         \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1 (BatchNormaliz (None, 64, 64, 128)  512         add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1 (Activation) (None, 64, 64, 128)  0           stage2_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_49 (ZeroPadding2 (None, 66, 66, 128)  0           stage2_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1 (Conv2D)     (None, 64, 64, 128)  147456      zero_padding2d_49[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2 (BatchNormaliz (None, 64, 64, 128)  512         stage2_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2 (Activation) (None, 64, 64, 128)  0           stage2_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_50 (ZeroPadding2 (None, 66, 66, 128)  0           stage2_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2 (Conv2D)     (None, 64, 64, 128)  147456      zero_padding2d_50[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 64, 64, 128)  0           stage2_unit4_conv2[0][0]         \n",
      "                                                                 add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 64, 64, 128)  512         add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 64, 64, 128)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_51 (ZeroPadding2 (None, 66, 66, 128)  0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 32, 32, 256)  294912      zero_padding2d_51[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 32, 32, 256)  1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 32, 32, 256)  0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_52 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_52[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 32, 32, 256)  32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 32, 32, 256)  0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 32, 32, 256)  1024        add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 32, 32, 256)  0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_53 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_53[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 32, 32, 256)  1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 32, 32, 256)  0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_54 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_54[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 32, 32, 256)  0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1 (BatchNormaliz (None, 32, 32, 256)  1024        add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1 (Activation) (None, 32, 32, 256)  0           stage3_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_55 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_55[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2 (BatchNormaliz (None, 32, 32, 256)  1024        stage3_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2 (Activation) (None, 32, 32, 256)  0           stage3_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_56 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_56[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 32, 32, 256)  0           stage3_unit3_conv2[0][0]         \n",
      "                                                                 add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1 (BatchNormaliz (None, 32, 32, 256)  1024        add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1 (Activation) (None, 32, 32, 256)  0           stage3_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_57 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_57[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2 (BatchNormaliz (None, 32, 32, 256)  1024        stage3_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2 (Activation) (None, 32, 32, 256)  0           stage3_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_58 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_58[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 32, 32, 256)  0           stage3_unit4_conv2[0][0]         \n",
      "                                                                 add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1 (BatchNormaliz (None, 32, 32, 256)  1024        add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1 (Activation) (None, 32, 32, 256)  0           stage3_unit5_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_59 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit5_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_59[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2 (BatchNormaliz (None, 32, 32, 256)  1024        stage3_unit5_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2 (Activation) (None, 32, 32, 256)  0           stage3_unit5_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_60 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit5_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_60[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 32, 32, 256)  0           stage3_unit5_conv2[0][0]         \n",
      "                                                                 add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1 (BatchNormaliz (None, 32, 32, 256)  1024        add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1 (Activation) (None, 32, 32, 256)  0           stage3_unit6_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_61 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit6_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_61[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2 (BatchNormaliz (None, 32, 32, 256)  1024        stage3_unit6_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2 (Activation) (None, 32, 32, 256)  0           stage3_unit6_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_62 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit6_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_62[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 32, 32, 256)  0           stage3_unit6_conv2[0][0]         \n",
      "                                                                 add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 32, 32, 256)  1024        add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 32, 32, 256)  0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_63 (ZeroPadding2 (None, 34, 34, 256)  0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 16, 16, 512)  1179648     zero_padding2d_63[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 16, 16, 512)  2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 16, 16, 512)  0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_64 (ZeroPadding2 (None, 18, 18, 512)  0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 16, 16, 512)  2359296     zero_padding2d_64[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 16, 16, 512)  131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 16, 16, 512)  0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 16, 16, 512)  2048        add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 16, 16, 512)  0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_65 (ZeroPadding2 (None, 18, 18, 512)  0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 16, 16, 512)  2359296     zero_padding2d_65[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 16, 16, 512)  2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 16, 16, 512)  0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_66 (ZeroPadding2 (None, 18, 18, 512)  0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 16, 16, 512)  2359296     zero_padding2d_66[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 16, 16, 512)  0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1 (BatchNormaliz (None, 16, 16, 512)  2048        add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1 (Activation) (None, 16, 16, 512)  0           stage4_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_67 (ZeroPadding2 (None, 18, 18, 512)  0           stage4_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1 (Conv2D)     (None, 16, 16, 512)  2359296     zero_padding2d_67[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2 (BatchNormaliz (None, 16, 16, 512)  2048        stage4_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2 (Activation) (None, 16, 16, 512)  0           stage4_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_68 (ZeroPadding2 (None, 18, 18, 512)  0           stage4_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2 (Conv2D)     (None, 16, 16, 512)  2359296     zero_padding2d_68[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 16, 16, 512)  0           stage4_unit3_conv2[0][0]         \n",
      "                                                                 add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 16, 16, 512)  2048        add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 16, 16, 512)  0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_upsampling (UpSa (None, 32, 32, 512)  0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_concat (Concaten (None, 32, 32, 768)  0           decoder_stage0_upsampling[0][0]  \n",
      "                                                                 stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_conv (Conv2D)   (None, 32, 32, 1024) 7077888     decoder_stage0_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_bn (BatchNormal (None, 32, 32, 1024) 4096        decoder_stage0a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_relu (Activatio (None, 32, 32, 1024) 0           decoder_stage0a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_conv (Conv2D)   (None, 32, 32, 1024) 9437184     decoder_stage0a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_bn (BatchNormal (None, 32, 32, 1024) 4096        decoder_stage0b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_relu (Activatio (None, 32, 32, 1024) 0           decoder_stage0b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_upsampling (UpSa (None, 64, 64, 1024) 0           decoder_stage0b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_concat (Concaten (None, 64, 64, 1152) 0           decoder_stage1_upsampling[0][0]  \n",
      "                                                                 stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_conv (Conv2D)   (None, 64, 64, 512)  5308416     decoder_stage1_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_bn (BatchNormal (None, 64, 64, 512)  2048        decoder_stage1a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_relu (Activatio (None, 64, 64, 512)  0           decoder_stage1a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_conv (Conv2D)   (None, 64, 64, 512)  2359296     decoder_stage1a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_bn (BatchNormal (None, 64, 64, 512)  2048        decoder_stage1b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_relu (Activatio (None, 64, 64, 512)  0           decoder_stage1b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_upsampling (UpSa (None, 128, 128, 512 0           decoder_stage1b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_concat (Concaten (None, 128, 128, 576 0           decoder_stage2_upsampling[0][0]  \n",
      "                                                                 stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_conv (Conv2D)   (None, 128, 128, 256 1327104     decoder_stage2_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_bn (BatchNormal (None, 128, 128, 256 1024        decoder_stage2a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_relu (Activatio (None, 128, 128, 256 0           decoder_stage2a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_conv (Conv2D)   (None, 128, 128, 256 589824      decoder_stage2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_bn (BatchNormal (None, 128, 128, 256 1024        decoder_stage2b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_relu (Activatio (None, 128, 128, 256 0           decoder_stage2b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_upsampling (UpSa (None, 256, 256, 256 0           decoder_stage2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_concat (Concaten (None, 256, 256, 320 0           decoder_stage3_upsampling[0][0]  \n",
      "                                                                 relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_conv (Conv2D)   (None, 256, 256, 128 368640      decoder_stage3_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_bn (BatchNormal (None, 256, 256, 128 512         decoder_stage3a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_relu (Activatio (None, 256, 256, 128 0           decoder_stage3a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_conv (Conv2D)   (None, 256, 256, 128 147456      decoder_stage3a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_bn (BatchNormal (None, 256, 256, 128 512         decoder_stage3b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_relu (Activatio (None, 256, 256, 128 0           decoder_stage3b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_upsampling (UpSa (None, 512, 512, 128 0           decoder_stage3b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_conv (Conv2D)   (None, 512, 512, 64) 73728       decoder_stage4_upsampling[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_bn (BatchNormal (None, 512, 512, 64) 256         decoder_stage4a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_relu (Activatio (None, 512, 512, 64) 0           decoder_stage4a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_conv (Conv2D)   (None, 512, 512, 64) 36864       decoder_stage4a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_bn (BatchNormal (None, 512, 512, 64) 256         decoder_stage4b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_relu (Activatio (None, 512, 512, 64) 0           decoder_stage4b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv2D)             (None, 512, 512, 3)  1731        decoder_stage4b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tanh (Activation)               (None, 512, 512, 3)  0           final_conv[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 48,046,476\n",
      "Trainable params: 26,751,430\n",
      "Non-trainable params: 21,295,046\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HiNe68yKsre-"
   },
   "outputs": [],
   "source": [
    "def build_gan(input_size):\n",
    "  # High res. and low res. images\n",
    "  img_lr = Input(shape=lr_shape)\n",
    "  # generate high res. version from low res.\n",
    "  fake_hr = generator(img_lr)\n",
    "  # extract image features of the generated img\n",
    "  fake_features = feature_loss(fake_hr)\n",
    "  # for the combined model we will only train the generator\n",
    "  discriminator.trainable = False\n",
    "  # Discriminator determines validity of generated high res. images\n",
    "  validity = discriminator(fake_hr)\n",
    "  combined = Model([img_lr], [validity, fake_features])\n",
    "  combined.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1e-3, 1], optimizer=optimizer)\n",
    "  return combined\n",
    "gan = build_gan(lr_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RcsHlVoCbj2N"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "KRrhIe8Dbm7e",
    "outputId": "b69f3953-cd82-4f30-d7cd-b39693a4a02c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 time: 0:00:01.630639\n",
      "1 time: 0:00:04.039198\n",
      "2 time: 0:00:05.595058\n",
      "3 time: 0:00:07.168828\n",
      "4 time: 0:00:08.724667\n",
      "5 time: 0:00:10.254598\n",
      "6 time: 0:00:11.792461\n",
      "7 time: 0:00:13.338349\n",
      "8 time: 0:00:14.862251\n",
      "9 time: 0:00:16.386204\n",
      "10 time: 0:00:17.919142\n",
      "11 time: 0:00:19.434062\n",
      "12 time: 0:00:20.962977\n",
      "13 time: 0:00:22.493879\n",
      "14 time: 0:00:24.006833\n",
      "15 time: 0:00:25.518816\n",
      "16 time: 0:00:27.046702\n",
      "17 time: 0:00:28.567656\n",
      "18 time: 0:00:30.083580\n",
      "19 time: 0:00:31.604512\n",
      "20 time: 0:00:33.134420\n",
      "21 time: 0:00:34.665325\n",
      "22 time: 0:00:36.189277\n",
      "23 time: 0:00:37.715209\n",
      "24 time: 0:00:39.249084\n",
      "25 time: 0:00:40.767024\n",
      "26 time: 0:00:42.285962\n",
      "27 time: 0:00:43.800932\n",
      "28 time: 0:00:45.329821\n",
      "29 time: 0:00:46.866737\n",
      "30 time: 0:00:48.394646\n",
      "31 time: 0:00:49.929519\n",
      "32 time: 0:00:51.454442\n",
      "33 time: 0:00:52.978369\n",
      "34 time: 0:00:54.498300\n",
      "35 time: 0:00:56.025216\n",
      "36 time: 0:00:57.550163\n",
      "37 time: 0:00:59.073065\n",
      "38 time: 0:01:00.603970\n",
      "39 time: 0:01:02.137889\n",
      "40 time: 0:01:03.660795\n",
      "41 time: 0:01:05.187739\n",
      "42 time: 0:01:06.721608\n",
      "43 time: 0:01:08.256503\n",
      "44 time: 0:01:09.786446\n",
      "45 time: 0:01:11.314358\n",
      "46 time: 0:01:12.840302\n",
      "47 time: 0:01:14.367222\n",
      "48 time: 0:01:15.901126\n",
      "49 time: 0:01:17.430052\n",
      "50 time: 0:01:18.962001\n",
      "51 time: 0:01:21.879233\n",
      "52 time: 0:01:23.415189\n",
      "53 time: 0:01:24.946092\n",
      "54 time: 0:01:26.486973\n",
      "55 time: 0:01:28.023843\n",
      "56 time: 0:01:29.557730\n",
      "57 time: 0:01:31.089688\n",
      "58 time: 0:01:32.616633\n",
      "59 time: 0:01:34.147509\n",
      "60 time: 0:01:35.680414\n",
      "61 time: 0:01:37.210341\n",
      "62 time: 0:01:38.738260\n",
      "63 time: 0:01:40.279153\n",
      "64 time: 0:01:41.810060\n",
      "65 time: 0:01:43.344983\n",
      "66 time: 0:01:44.889822\n",
      "67 time: 0:01:46.423807\n",
      "68 time: 0:01:47.958676\n",
      "69 time: 0:01:49.497560\n",
      "70 time: 0:01:51.028493\n",
      "71 time: 0:01:52.571362\n",
      "72 time: 0:01:54.103272\n",
      "73 time: 0:01:55.634193\n",
      "74 time: 0:01:57.175082\n",
      "75 time: 0:01:58.705988\n",
      "76 time: 0:02:00.239885\n",
      "77 time: 0:02:01.769815\n",
      "78 time: 0:02:03.304688\n",
      "79 time: 0:02:04.842576\n",
      "80 time: 0:02:06.379465\n",
      "81 time: 0:02:07.917352\n",
      "82 time: 0:02:09.443294\n",
      "83 time: 0:02:10.978172\n",
      "84 time: 0:02:12.519044\n",
      "85 time: 0:02:14.052942\n",
      "86 time: 0:02:15.577864\n",
      "87 time: 0:02:17.121757\n",
      "88 time: 0:02:18.655654\n",
      "89 time: 0:02:20.187556\n",
      "90 time: 0:02:21.719437\n",
      "91 time: 0:02:23.250372\n",
      "92 time: 0:02:24.786235\n",
      "93 time: 0:02:26.318139\n",
      "94 time: 0:02:27.860014\n",
      "95 time: 0:02:29.388925\n",
      "96 time: 0:02:30.922822\n",
      "97 time: 0:02:32.459740\n",
      "98 time: 0:02:33.990642\n",
      "99 time: 0:02:35.522575\n",
      "100 time: 0:02:37.061432\n",
      "101 time: 0:02:39.424113\n",
      "102 time: 0:02:40.954043\n",
      "103 time: 0:02:42.491918\n",
      "104 time: 0:02:44.030848\n",
      "105 time: 0:02:45.586702\n",
      "106 time: 0:02:47.147500\n",
      "107 time: 0:02:48.688421\n",
      "108 time: 0:02:50.230299\n",
      "109 time: 0:02:51.757216\n",
      "110 time: 0:02:53.294127\n",
      "111 time: 0:02:54.838999\n",
      "112 time: 0:02:56.375864\n",
      "113 time: 0:02:57.913749\n",
      "114 time: 0:02:59.446649\n",
      "115 time: 0:03:00.982564\n",
      "116 time: 0:03:02.524443\n",
      "117 time: 0:03:04.056321\n",
      "118 time: 0:03:05.594208\n",
      "119 time: 0:03:07.129104\n",
      "120 time: 0:03:08.665017\n",
      "121 time: 0:03:10.198892\n",
      "122 time: 0:03:11.726806\n",
      "123 time: 0:03:13.262728\n",
      "124 time: 0:03:14.789614\n",
      "125 time: 0:03:16.328498\n",
      "126 time: 0:03:17.861427\n",
      "127 time: 0:03:19.388315\n",
      "128 time: 0:03:20.922240\n",
      "129 time: 0:03:22.451140\n",
      "130 time: 0:03:23.983026\n",
      "131 time: 0:03:25.514957\n",
      "132 time: 0:03:27.052817\n",
      "133 time: 0:03:28.586742\n",
      "134 time: 0:03:30.111636\n",
      "135 time: 0:03:31.644596\n",
      "136 time: 0:03:33.182447\n",
      "137 time: 0:03:34.712356\n",
      "138 time: 0:03:36.243261\n",
      "139 time: 0:03:37.770178\n",
      "140 time: 0:03:39.297093\n",
      "141 time: 0:03:40.825007\n",
      "142 time: 0:03:42.357908\n",
      "143 time: 0:03:43.890807\n",
      "144 time: 0:03:45.417747\n",
      "145 time: 0:03:46.961595\n",
      "146 time: 0:03:48.501477\n",
      "147 time: 0:03:50.039390\n",
      "148 time: 0:03:51.574281\n",
      "149 time: 0:03:53.113165\n",
      "150 time: 0:03:54.648037\n",
      "151 time: 0:03:57.004768\n",
      "152 time: 0:03:58.537709\n",
      "153 time: 0:04:00.076594\n",
      "154 time: 0:04:01.605504\n",
      "155 time: 0:04:03.142394\n",
      "156 time: 0:04:04.680281\n",
      "157 time: 0:04:06.208218\n",
      "158 time: 0:04:07.745084\n",
      "159 time: 0:04:09.277015\n",
      "160 time: 0:04:10.805925\n",
      "161 time: 0:04:12.347775\n",
      "162 time: 0:04:13.881672\n",
      "163 time: 0:04:15.440502\n",
      "164 time: 0:04:16.992374\n",
      "165 time: 0:04:18.527248\n",
      "166 time: 0:04:20.068157\n",
      "167 time: 0:04:21.601057\n",
      "168 time: 0:04:23.136950\n",
      "169 time: 0:04:24.662868\n",
      "170 time: 0:04:26.192776\n",
      "171 time: 0:04:27.721719\n",
      "172 time: 0:04:29.257634\n",
      "173 time: 0:04:30.799487\n",
      "174 time: 0:04:32.322442\n",
      "175 time: 0:04:33.856312\n",
      "176 time: 0:04:35.389240\n",
      "177 time: 0:04:36.928119\n",
      "178 time: 0:04:38.469972\n",
      "179 time: 0:04:40.007859\n",
      "180 time: 0:04:41.541766\n",
      "181 time: 0:04:43.075683\n",
      "182 time: 0:04:44.632494\n",
      "183 time: 0:04:46.166388\n",
      "184 time: 0:04:47.720261\n",
      "185 time: 0:04:49.260137\n",
      "186 time: 0:04:50.801017\n",
      "187 time: 0:04:52.334890\n",
      "188 time: 0:04:53.865796\n",
      "189 time: 0:04:55.402685\n",
      "190 time: 0:04:56.933591\n",
      "191 time: 0:04:58.467489\n",
      "192 time: 0:05:00.002410\n",
      "193 time: 0:05:01.538284\n",
      "194 time: 0:05:03.073171\n",
      "195 time: 0:05:04.606093\n",
      "196 time: 0:05:06.144989\n",
      "197 time: 0:05:07.683861\n",
      "198 time: 0:05:09.214780\n",
      "199 time: 0:05:10.754661\n",
      "200 time: 0:05:12.301545\n",
      "201 time: 0:05:14.646273\n",
      "202 time: 0:05:16.181194\n",
      "203 time: 0:05:17.710108\n",
      "204 time: 0:05:19.234026\n",
      "205 time: 0:05:20.769924\n",
      "206 time: 0:05:22.299804\n",
      "207 time: 0:05:23.825745\n",
      "208 time: 0:05:25.359621\n",
      "209 time: 0:05:26.886537\n",
      "210 time: 0:05:28.411481\n",
      "211 time: 0:05:29.935410\n",
      "212 time: 0:05:31.465313\n",
      "213 time: 0:05:32.995198\n",
      "214 time: 0:05:34.518125\n",
      "215 time: 0:05:36.058030\n",
      "216 time: 0:05:37.593926\n",
      "217 time: 0:05:39.121844\n",
      "218 time: 0:05:40.648729\n",
      "219 time: 0:05:42.179657\n",
      "220 time: 0:05:43.695580\n",
      "221 time: 0:05:45.227483\n",
      "222 time: 0:05:46.754423\n",
      "223 time: 0:05:48.281315\n",
      "224 time: 0:05:49.809256\n",
      "225 time: 0:05:51.350135\n",
      "226 time: 0:05:52.884005\n",
      "227 time: 0:05:54.413927\n",
      "228 time: 0:05:55.950851\n",
      "229 time: 0:05:57.481747\n",
      "230 time: 0:05:59.012653\n",
      "231 time: 0:06:00.545576\n",
      "232 time: 0:06:02.077481\n",
      "233 time: 0:06:03.603375\n",
      "234 time: 0:06:05.146271\n",
      "235 time: 0:06:06.683138\n",
      "236 time: 0:06:08.215042\n",
      "237 time: 0:06:09.753925\n",
      "238 time: 0:06:11.282858\n",
      "239 time: 0:06:12.819725\n",
      "240 time: 0:06:14.342676\n",
      "241 time: 0:06:15.878556\n",
      "242 time: 0:06:17.410474\n",
      "243 time: 0:06:18.938388\n",
      "244 time: 0:06:20.457340\n",
      "245 time: 0:06:21.992220\n",
      "246 time: 0:06:23.517164\n",
      "247 time: 0:06:25.055057\n",
      "248 time: 0:06:26.575977\n",
      "249 time: 0:06:28.118835\n",
      "250 time: 0:06:29.649740\n",
      "251 time: 0:06:32.001450\n",
      "252 time: 0:06:33.534373\n",
      "253 time: 0:06:35.074239\n",
      "254 time: 0:06:36.598156\n",
      "255 time: 0:06:38.130062\n",
      "256 time: 0:06:39.656004\n",
      "257 time: 0:06:41.183905\n",
      "258 time: 0:06:42.712812\n",
      "259 time: 0:06:44.238721\n",
      "260 time: 0:06:45.789604\n",
      "261 time: 0:06:47.332447\n",
      "262 time: 0:06:48.872328\n",
      "263 time: 0:06:50.411217\n",
      "264 time: 0:06:51.945137\n",
      "265 time: 0:06:53.483994\n",
      "266 time: 0:06:55.020905\n",
      "267 time: 0:06:56.552832\n",
      "268 time: 0:06:58.092691\n",
      "269 time: 0:06:59.631599\n",
      "270 time: 0:07:01.167495\n",
      "271 time: 0:07:02.691413\n",
      "272 time: 0:07:04.221299\n",
      "273 time: 0:07:05.761179\n",
      "274 time: 0:07:07.292114\n",
      "275 time: 0:07:08.826007\n",
      "276 time: 0:07:10.363870\n",
      "277 time: 0:07:11.884810\n",
      "278 time: 0:07:13.413713\n",
      "279 time: 0:07:14.952624\n",
      "280 time: 0:07:16.479536\n",
      "281 time: 0:07:18.024382\n",
      "282 time: 0:07:19.566285\n",
      "283 time: 0:07:21.097175\n",
      "284 time: 0:07:22.623082\n",
      "285 time: 0:07:24.148073\n",
      "286 time: 0:07:25.686955\n",
      "287 time: 0:07:27.219879\n",
      "288 time: 0:07:28.748793\n",
      "289 time: 0:07:30.278704\n",
      "290 time: 0:07:31.817559\n",
      "291 time: 0:07:33.343500\n",
      "292 time: 0:07:34.868429\n",
      "293 time: 0:07:36.392354\n",
      "294 time: 0:07:37.925224\n",
      "295 time: 0:07:39.447180\n",
      "296 time: 0:07:40.969082\n",
      "297 time: 0:07:42.502980\n",
      "298 time: 0:07:44.037898\n",
      "299 time: 0:07:45.566813\n",
      "300 time: 0:07:47.095724\n",
      "301 time: 0:07:49.453420\n",
      "302 time: 0:07:50.982302\n",
      "303 time: 0:07:52.518247\n",
      "304 time: 0:07:54.057131\n",
      "305 time: 0:07:55.591029\n",
      "306 time: 0:07:57.138890\n",
      "307 time: 0:07:58.673807\n",
      "308 time: 0:08:00.201729\n",
      "309 time: 0:08:01.730631\n",
      "310 time: 0:08:03.269516\n",
      "311 time: 0:08:04.795434\n",
      "312 time: 0:08:06.329309\n",
      "313 time: 0:08:07.854231\n",
      "314 time: 0:08:09.383172\n",
      "315 time: 0:08:10.920050\n",
      "316 time: 0:08:12.449939\n",
      "317 time: 0:08:13.986856\n",
      "318 time: 0:08:15.518754\n",
      "319 time: 0:08:17.048640\n",
      "320 time: 0:08:18.578548\n",
      "321 time: 0:08:20.115464\n",
      "322 time: 0:08:21.655319\n",
      "323 time: 0:08:23.195201\n",
      "324 time: 0:08:24.735082\n",
      "325 time: 0:08:26.264991\n",
      "326 time: 0:08:27.797899\n",
      "327 time: 0:08:29.328823\n",
      "328 time: 0:08:30.858704\n",
      "329 time: 0:08:32.397602\n",
      "330 time: 0:08:33.932490\n",
      "331 time: 0:08:35.467403\n",
      "332 time: 0:08:37.001298\n",
      "333 time: 0:08:38.553125\n",
      "334 time: 0:08:40.077077\n",
      "335 time: 0:08:41.608952\n",
      "336 time: 0:08:43.147859\n",
      "337 time: 0:08:44.691715\n",
      "D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 time: 0:00:25.616912\n",
      "2 time: 0:00:27.183970\n",
      "3 time: 0:00:28.739407\n",
      "4 time: 0:00:30.264332\n",
      "5 time: 0:00:31.780177\n",
      "6 time: 0:00:33.274620\n",
      "7 time: 0:00:34.781588\n",
      "8 time: 0:00:36.290271\n",
      "9 time: 0:00:37.781286\n",
      "10 time: 0:00:39.281705\n",
      "11 time: 0:00:40.780559\n",
      "12 time: 0:00:42.311467\n",
      "13 time: 0:00:43.815825\n",
      "14 time: 0:00:45.300392\n",
      "15 time: 0:00:46.792563\n",
      "16 time: 0:00:48.286537\n",
      "17 time: 0:00:49.818312\n",
      "18 time: 0:00:51.307751\n",
      "19 time: 0:00:52.830256\n",
      "20 time: 0:00:54.352187\n",
      "21 time: 0:00:55.838223\n",
      "22 time: 0:00:57.328808\n",
      "23 time: 0:00:58.809883\n",
      "24 time: 0:01:00.300755\n",
      "25 time: 0:01:01.792245\n",
      "26 time: 0:01:03.278899\n",
      "27 time: 0:01:04.809780\n",
      "28 time: 0:01:06.341316\n",
      "29 time: 0:01:07.843299\n",
      "30 time: 0:01:09.341666\n",
      "31 time: 0:01:10.826414\n",
      "32 time: 0:01:12.358319\n",
      "33 time: 0:01:13.958042\n",
      "34 time: 0:01:15.485954\n",
      "35 time: 0:01:17.002886\n",
      "36 time: 0:01:18.564945\n",
      "37 time: 0:01:20.115182\n",
      "38 time: 0:01:21.652062\n",
      "39 time: 0:01:23.216887\n",
      "40 time: 0:01:24.727894\n",
      "41 time: 0:01:26.251837\n",
      "42 time: 0:01:27.795809\n",
      "43 time: 0:01:29.340543\n",
      "44 time: 0:01:30.848870\n",
      "45 time: 0:01:32.377782\n",
      "46 time: 0:01:33.891735\n",
      "47 time: 0:01:35.377172\n",
      "48 time: 0:01:36.898112\n",
      "49 time: 0:01:38.400135\n",
      "50 time: 0:01:39.948995\n",
      "51 time: 0:01:42.306692\n",
      "52 time: 0:01:43.804484\n",
      "53 time: 0:01:45.374541\n",
      "54 time: 0:01:46.962456\n",
      "55 time: 0:01:48.560160\n",
      "56 time: 0:01:50.059337\n",
      "57 time: 0:01:51.556317\n",
      "58 time: 0:01:53.048298\n",
      "59 time: 0:01:54.535162\n",
      "60 time: 0:01:56.027279\n",
      "61 time: 0:01:57.518388\n",
      "62 time: 0:01:59.006123\n",
      "63 time: 0:02:00.523045\n",
      "64 time: 0:02:02.033703\n",
      "65 time: 0:02:03.526702\n",
      "66 time: 0:02:05.016719\n",
      "67 time: 0:02:06.506209\n",
      "68 time: 0:02:08.044598\n",
      "69 time: 0:02:09.523465\n",
      "70 time: 0:02:11.012454\n",
      "71 time: 0:02:12.550359\n",
      "72 time: 0:02:14.072273\n",
      "73 time: 0:02:15.602183\n",
      "74 time: 0:02:17.120125\n",
      "75 time: 0:02:18.609948\n",
      "76 time: 0:02:20.101402\n",
      "77 time: 0:02:21.610370\n",
      "78 time: 0:02:23.123903\n",
      "79 time: 0:02:24.652293\n",
      "80 time: 0:02:26.148343\n",
      "81 time: 0:02:27.678478\n",
      "82 time: 0:02:29.252270\n",
      "83 time: 0:02:30.795114\n",
      "84 time: 0:02:32.364108\n",
      "85 time: 0:02:33.936294\n",
      "86 time: 0:02:35.474433\n",
      "87 time: 0:02:36.998207\n",
      "88 time: 0:02:38.544062\n",
      "89 time: 0:02:40.091994\n",
      "90 time: 0:02:41.611752\n",
      "91 time: 0:02:43.109050\n",
      "92 time: 0:02:44.635152\n",
      "93 time: 0:02:46.160167\n",
      "94 time: 0:02:47.718068\n",
      "95 time: 0:02:49.252634\n",
      "96 time: 0:02:50.813325\n",
      "97 time: 0:02:52.325767\n",
      "98 time: 0:02:53.848750\n",
      "99 time: 0:02:55.364102\n",
      "100 time: 0:02:56.883040\n",
      "101 time: 0:02:59.244343\n",
      "102 time: 0:03:00.768405\n",
      "103 time: 0:03:02.252623\n",
      "104 time: 0:03:03.796495\n",
      "105 time: 0:03:05.326605\n",
      "106 time: 0:03:06.860891\n",
      "107 time: 0:03:08.356406\n",
      "108 time: 0:03:09.838769\n",
      "109 time: 0:03:11.330803\n",
      "110 time: 0:03:12.818788\n",
      "111 time: 0:03:14.304847\n",
      "112 time: 0:03:15.790608\n",
      "113 time: 0:03:17.279850\n",
      "114 time: 0:03:18.765851\n",
      "115 time: 0:03:20.251437\n",
      "116 time: 0:03:21.735959\n",
      "117 time: 0:03:23.217811\n",
      "118 time: 0:03:24.707058\n",
      "119 time: 0:03:26.198074\n",
      "120 time: 0:03:27.680729\n",
      "121 time: 0:03:29.158757\n",
      "122 time: 0:03:30.643807\n",
      "123 time: 0:03:32.134529\n",
      "124 time: 0:03:33.619559\n",
      "125 time: 0:03:35.101412\n",
      "126 time: 0:03:36.582271\n",
      "127 time: 0:03:38.067849\n",
      "128 time: 0:03:39.550051\n",
      "129 time: 0:03:41.041463\n",
      "130 time: 0:03:42.528181\n",
      "131 time: 0:03:44.008230\n",
      "132 time: 0:03:45.494229\n",
      "133 time: 0:03:46.976563\n",
      "134 time: 0:03:48.468621\n",
      "135 time: 0:03:49.950354\n",
      "136 time: 0:03:51.436899\n",
      "137 time: 0:03:52.924153\n",
      "138 time: 0:03:54.411000\n",
      "139 time: 0:03:55.896104\n",
      "140 time: 0:03:57.381117\n",
      "141 time: 0:03:58.866166\n",
      "142 time: 0:04:00.357965\n",
      "143 time: 0:04:01.849857\n",
      "144 time: 0:04:03.335868\n",
      "145 time: 0:04:04.835454\n",
      "146 time: 0:04:06.322569\n",
      "147 time: 0:04:07.805090\n",
      "148 time: 0:04:09.294222\n",
      "149 time: 0:04:10.782958\n",
      "150 time: 0:04:12.267723\n",
      "151 time: 0:04:14.592892\n",
      "152 time: 0:04:16.082909\n",
      "153 time: 0:04:17.563949\n",
      "154 time: 0:04:19.049905\n",
      "155 time: 0:04:20.548898\n",
      "156 time: 0:04:22.036921\n",
      "157 time: 0:04:23.519680\n",
      "158 time: 0:04:25.012701\n",
      "159 time: 0:04:26.501710\n",
      "160 time: 0:04:27.984764\n",
      "161 time: 0:04:29.465772\n",
      "162 time: 0:04:30.957814\n",
      "163 time: 0:04:32.440844\n",
      "164 time: 0:04:33.925006\n",
      "165 time: 0:04:35.410036\n",
      "166 time: 0:04:36.908494\n",
      "167 time: 0:04:38.399435\n",
      "168 time: 0:04:39.884325\n",
      "169 time: 0:04:41.377373\n",
      "170 time: 0:04:42.859049\n",
      "171 time: 0:04:44.336304\n",
      "172 time: 0:04:45.823333\n",
      "173 time: 0:04:47.303752\n",
      "174 time: 0:04:48.789365\n",
      "175 time: 0:04:50.272891\n",
      "176 time: 0:04:51.760427\n",
      "177 time: 0:04:53.254901\n",
      "178 time: 0:04:54.743584\n",
      "179 time: 0:04:56.236479\n",
      "180 time: 0:04:57.720087\n",
      "181 time: 0:04:59.202539\n",
      "182 time: 0:05:00.677595\n",
      "183 time: 0:05:02.165639\n",
      "184 time: 0:05:03.642692\n",
      "185 time: 0:05:05.126719\n",
      "186 time: 0:05:06.680931\n",
      "187 time: 0:05:08.176992\n",
      "188 time: 0:05:09.661371\n",
      "189 time: 0:05:11.144379\n",
      "190 time: 0:05:12.631590\n",
      "191 time: 0:05:14.113650\n",
      "192 time: 0:05:15.598620\n",
      "193 time: 0:05:17.081545\n",
      "194 time: 0:05:18.563634\n",
      "195 time: 0:05:20.041784\n",
      "196 time: 0:05:21.528513\n",
      "197 time: 0:05:23.016328\n",
      "198 time: 0:05:24.519375\n",
      "199 time: 0:05:26.008366\n",
      "200 time: 0:05:27.494528\n",
      "201 time: 0:05:29.804672\n",
      "202 time: 0:05:31.296991\n",
      "203 time: 0:05:32.783094\n",
      "204 time: 0:05:34.269124\n",
      "205 time: 0:05:35.757152\n",
      "206 time: 0:05:37.245173\n",
      "207 time: 0:05:38.730635\n",
      "208 time: 0:05:40.225658\n",
      "209 time: 0:05:41.714110\n",
      "210 time: 0:05:43.199248\n",
      "211 time: 0:05:44.691473\n",
      "212 time: 0:05:46.181896\n",
      "213 time: 0:05:47.669690\n",
      "214 time: 0:05:49.147159\n",
      "215 time: 0:05:50.654509\n",
      "216 time: 0:05:52.149514\n",
      "217 time: 0:05:53.647508\n",
      "218 time: 0:05:55.142534\n",
      "219 time: 0:05:56.655475\n",
      "220 time: 0:05:58.152464\n",
      "221 time: 0:05:59.644475\n",
      "222 time: 0:06:01.139479\n",
      "223 time: 0:06:02.633484\n",
      "224 time: 0:06:04.120509\n",
      "225 time: 0:06:05.613519\n",
      "226 time: 0:06:07.119132\n",
      "227 time: 0:06:08.600174\n",
      "228 time: 0:06:10.083328\n",
      "229 time: 0:06:11.569812\n",
      "230 time: 0:06:13.066234\n",
      "231 time: 0:06:14.552371\n",
      "232 time: 0:06:16.036219\n",
      "233 time: 0:06:17.525161\n",
      "234 time: 0:06:19.010432\n",
      "235 time: 0:06:20.487457\n",
      "236 time: 0:06:21.990900\n",
      "237 time: 0:06:23.482030\n",
      "238 time: 0:06:24.967591\n",
      "239 time: 0:06:26.446983\n",
      "240 time: 0:06:27.930363\n",
      "241 time: 0:06:29.417405\n",
      "242 time: 0:06:30.903434\n",
      "243 time: 0:06:32.385503\n",
      "244 time: 0:06:33.863995\n",
      "245 time: 0:06:35.350105\n",
      "246 time: 0:06:36.836621\n",
      "247 time: 0:06:38.321298\n",
      "248 time: 0:06:39.806440\n",
      "249 time: 0:06:41.298462\n",
      "250 time: 0:06:42.779626\n",
      "251 time: 0:06:45.082659\n",
      "252 time: 0:06:46.565624\n",
      "253 time: 0:06:48.049443\n",
      "254 time: 0:06:49.532025\n",
      "255 time: 0:06:51.018643\n",
      "256 time: 0:06:52.504786\n",
      "257 time: 0:06:53.990329\n",
      "258 time: 0:06:55.475379\n",
      "259 time: 0:06:56.961373\n",
      "260 time: 0:06:58.444875\n",
      "261 time: 0:06:59.931900\n",
      "262 time: 0:07:01.426060\n",
      "263 time: 0:07:02.904586\n",
      "264 time: 0:07:04.385621\n",
      "265 time: 0:07:05.871313\n",
      "266 time: 0:07:07.346367\n",
      "267 time: 0:07:08.852762\n",
      "268 time: 0:07:10.340218\n",
      "269 time: 0:07:11.827732\n",
      "270 time: 0:07:13.309011\n",
      "271 time: 0:07:14.796716\n",
      "272 time: 0:07:16.292647\n",
      "273 time: 0:07:17.773635\n",
      "274 time: 0:07:19.262602\n",
      "275 time: 0:07:20.739231\n",
      "276 time: 0:07:22.225136\n",
      "277 time: 0:07:23.709282\n",
      "278 time: 0:07:25.191471\n",
      "279 time: 0:07:26.672507\n",
      "280 time: 0:07:28.149294\n",
      "281 time: 0:07:29.629583\n",
      "282 time: 0:07:31.121019\n",
      "283 time: 0:07:32.613400\n",
      "284 time: 0:07:34.093579\n",
      "285 time: 0:07:35.574060\n",
      "286 time: 0:07:37.053592\n",
      "287 time: 0:07:38.535394\n",
      "288 time: 0:07:40.014507\n",
      "289 time: 0:07:41.496573\n",
      "290 time: 0:07:42.982324\n",
      "291 time: 0:07:44.474335\n",
      "292 time: 0:07:45.963376\n",
      "293 time: 0:07:47.437706\n",
      "294 time: 0:07:48.925360\n",
      "295 time: 0:07:50.411612\n",
      "296 time: 0:07:51.892855\n",
      "297 time: 0:07:53.373703\n",
      "298 time: 0:07:54.863736\n",
      "299 time: 0:07:56.351110\n",
      "300 time: 0:07:57.835142\n",
      "301 time: 0:08:00.138008\n",
      "302 time: 0:08:01.618573\n",
      "303 time: 0:08:03.096501\n",
      "304 time: 0:08:04.594174\n",
      "305 time: 0:08:06.082241\n",
      "306 time: 0:08:07.559968\n",
      "307 time: 0:08:09.037493\n",
      "308 time: 0:08:10.516589\n",
      "309 time: 0:08:12.003734\n",
      "310 time: 0:08:13.488763\n",
      "311 time: 0:08:14.978133\n",
      "312 time: 0:08:16.465896\n",
      "313 time: 0:08:17.944941\n",
      "314 time: 0:08:19.426000\n",
      "315 time: 0:08:20.912059\n",
      "316 time: 0:08:22.395735\n",
      "317 time: 0:08:23.881244\n",
      "318 time: 0:08:25.362888\n",
      "319 time: 0:08:26.849974\n",
      "320 time: 0:08:28.322751\n",
      "321 time: 0:08:29.799177\n",
      "322 time: 0:08:31.286217\n",
      "323 time: 0:08:32.765043\n",
      "324 time: 0:08:34.248031\n",
      "325 time: 0:08:35.735895\n",
      "326 time: 0:08:37.230624\n",
      "327 time: 0:08:38.710661\n",
      "328 time: 0:08:40.191889\n",
      "329 time: 0:08:41.681678\n",
      "330 time: 0:08:43.162135\n",
      "331 time: 0:08:44.646549\n",
      "332 time: 0:08:46.129817\n",
      "333 time: 0:08:47.606925\n",
      "334 time: 0:08:49.084670\n",
      "335 time: 0:08:50.565100\n",
      "336 time: 0:08:52.056080\n",
      "337 time: 0:08:53.537840\n",
      "338 time: 0:08:55.022871\n",
      "339 time: 0:08:56.510796\n",
      "340 time: 0:08:57.990998\n",
      "341 time: 0:08:59.475993\n",
      "342 time: 0:09:00.959108\n",
      "343 time: 0:09:02.443411\n",
      "344 time: 0:09:03.920741\n",
      "345 time: 0:09:05.406837\n",
      "346 time: 0:09:06.889403\n",
      "347 time: 0:09:08.383408\n",
      "348 time: 0:09:09.862490\n",
      "349 time: 0:09:11.347720\n",
      "350 time: 0:09:12.830109\n",
      "351 time: 0:09:15.124232\n",
      "352 time: 0:09:16.612485\n",
      "353 time: 0:09:18.096377\n",
      "354 time: 0:09:19.581551\n",
      "355 time: 0:09:21.060108\n",
      "356 time: 0:09:22.544333\n",
      "357 time: 0:09:24.036665\n",
      "358 time: 0:09:25.519125\n",
      "359 time: 0:09:27.001163\n",
      "360 time: 0:09:28.483165\n",
      "361 time: 0:09:29.965003\n",
      "362 time: 0:09:31.451089\n",
      "363 time: 0:09:32.930589\n",
      "364 time: 0:09:34.414417\n",
      "365 time: 0:09:35.897423\n",
      "366 time: 0:09:37.373478\n",
      "367 time: 0:09:38.857942\n",
      "368 time: 0:09:40.347012\n",
      "369 time: 0:09:41.828380\n",
      "370 time: 0:09:43.319436\n",
      "371 time: 0:09:44.804737\n",
      "372 time: 0:09:46.293028\n",
      "373 time: 0:09:47.775316\n",
      "374 time: 0:09:49.246386\n",
      "375 time: 0:09:50.727451\n",
      "376 time: 0:09:52.211634\n",
      "377 time: 0:09:53.696777\n",
      "378 time: 0:09:55.177865\n",
      "379 time: 0:09:56.706272\n",
      "380 time: 0:09:58.221247\n",
      "381 time: 0:09:59.712234\n",
      "382 time: 0:10:01.210364\n",
      "383 time: 0:10:02.705776\n",
      "384 time: 0:10:04.221545\n",
      "385 time: 0:10:05.738141\n",
      "386 time: 0:10:07.228158\n",
      "387 time: 0:10:08.708373\n",
      "388 time: 0:10:10.191226\n",
      "389 time: 0:10:11.676030\n",
      "390 time: 0:10:13.167679\n",
      "391 time: 0:10:14.646975\n",
      "392 time: 0:10:16.140064\n",
      "393 time: 0:10:17.755898\n",
      "394 time: 0:10:19.352648\n",
      "395 time: 0:10:20.973315\n",
      "396 time: 0:10:22.583011\n",
      "397 time: 0:10:24.159901\n",
      "398 time: 0:10:25.681834\n",
      "399 time: 0:10:27.219997\n",
      "400 time: 0:10:28.774221\n",
      "401 time: 0:10:31.145566\n",
      "402 time: 0:10:32.648915\n",
      "403 time: 0:10:34.130849\n",
      "404 time: 0:10:35.657463\n",
      "405 time: 0:10:37.209832\n",
      "406 time: 0:10:38.753649\n",
      "407 time: 0:10:40.258628\n",
      "408 time: 0:10:41.773770\n",
      "409 time: 0:10:43.337611\n",
      "410 time: 0:10:44.869482\n",
      "411 time: 0:10:46.407386\n",
      "412 time: 0:10:48.057958\n",
      "413 time: 0:10:49.703570\n",
      "414 time: 0:10:51.403520\n",
      "415 time: 0:10:53.038249\n",
      "416 time: 0:10:54.693361\n",
      "417 time: 0:10:56.379000\n",
      "418 time: 0:10:58.079486\n",
      "419 time: 0:10:59.698663\n",
      "420 time: 0:11:01.281908\n",
      "421 time: 0:11:02.842695\n",
      "422 time: 0:11:04.414247\n",
      "423 time: 0:11:05.988192\n",
      "424 time: 0:11:07.563133\n",
      "425 time: 0:11:09.131167\n",
      "426 time: 0:11:10.696543\n",
      "427 time: 0:11:12.259551\n",
      "428 time: 0:11:13.824692\n",
      "429 time: 0:11:15.381693\n",
      "430 time: 0:11:16.966056\n",
      "431 time: 0:11:18.524275\n",
      "432 time: 0:11:20.089544\n",
      "433 time: 0:11:21.658087\n",
      "434 time: 0:11:23.230842\n",
      "435 time: 0:11:24.804620\n",
      "436 time: 0:11:26.366208\n",
      "437 time: 0:11:27.925135\n",
      "438 time: 0:11:29.472398\n",
      "439 time: 0:11:31.031900\n",
      "440 time: 0:11:32.597310\n",
      "441 time: 0:11:34.150908\n",
      "442 time: 0:11:35.700315\n",
      "443 time: 0:11:37.255573\n",
      "444 time: 0:11:38.828743\n",
      "445 time: 0:11:40.384833\n",
      "446 time: 0:11:41.939723\n",
      "447 time: 0:11:43.510649\n",
      "448 time: 0:11:45.068175\n",
      "449 time: 0:11:46.628538\n",
      "450 time: 0:11:48.202379\n",
      "451 time: 0:11:50.612942\n",
      "452 time: 0:11:52.180226\n",
      "453 time: 0:11:53.748379\n",
      "454 time: 0:11:55.305127\n",
      "455 time: 0:11:56.860202\n",
      "456 time: 0:11:58.416519\n",
      "457 time: 0:11:59.973492\n",
      "458 time: 0:12:01.541744\n",
      "459 time: 0:12:03.103183\n",
      "460 time: 0:12:04.670175\n",
      "461 time: 0:12:06.238638\n",
      "462 time: 0:12:07.794583\n",
      "463 time: 0:12:09.350076\n",
      "464 time: 0:12:10.906871\n",
      "465 time: 0:12:12.459524\n",
      "466 time: 0:12:14.034464\n",
      "467 time: 0:12:15.595270\n",
      "468 time: 0:12:17.151824\n",
      "469 time: 0:12:18.708129\n",
      "470 time: 0:12:20.285496\n",
      "471 time: 0:12:21.842504\n",
      "472 time: 0:12:23.409468\n",
      "473 time: 0:12:24.972205\n",
      "474 time: 0:12:26.538740\n",
      "475 time: 0:12:28.100495\n",
      "476 time: 0:12:29.654737\n",
      "477 time: 0:12:31.211450\n",
      "478 time: 0:12:32.766076\n",
      "479 time: 0:12:34.323061\n",
      "480 time: 0:12:35.881277\n",
      "481 time: 0:12:37.450984\n",
      "482 time: 0:12:38.997116\n",
      "483 time: 0:12:40.547406\n",
      "484 time: 0:12:42.110132\n",
      "485 time: 0:12:43.664758\n",
      "486 time: 0:12:45.224584\n",
      "487 time: 0:12:46.792044\n",
      "488 time: 0:12:48.358803\n",
      "489 time: 0:12:49.919408\n",
      "490 time: 0:12:51.483989\n",
      "491 time: 0:12:53.051598\n",
      "492 time: 0:12:54.612147\n",
      "493 time: 0:12:56.176469\n",
      "494 time: 0:12:57.737918\n",
      "495 time: 0:12:59.304586\n",
      "496 time: 0:13:00.866494\n",
      "497 time: 0:13:02.435524\n",
      "498 time: 0:13:04.005497\n",
      "499 time: 0:13:05.572235\n",
      "500 time: 0:13:07.133386\n",
      "501 time: 0:13:09.569858\n",
      "502 time: 0:13:11.141418\n",
      "503 time: 0:13:12.711032\n",
      "504 time: 0:13:14.274605\n",
      "505 time: 0:13:15.840598\n",
      "506 time: 0:13:17.411613\n",
      "507 time: 0:13:18.977003\n",
      "508 time: 0:13:20.547144\n",
      "509 time: 0:13:22.112009\n",
      "510 time: 0:13:23.669909\n",
      "511 time: 0:13:25.245356\n",
      "512 time: 0:13:26.805059\n",
      "513 time: 0:13:28.363844\n",
      "514 time: 0:13:29.921130\n",
      "515 time: 0:13:31.483723\n",
      "516 time: 0:13:33.041223\n",
      "517 time: 0:13:34.602522\n",
      "518 time: 0:13:36.166024\n",
      "519 time: 0:13:37.718059\n",
      "520 time: 0:13:39.266788\n",
      "521 time: 0:13:40.844070\n",
      "522 time: 0:13:42.410052\n",
      "523 time: 0:13:43.961615\n",
      "524 time: 0:13:45.521362\n",
      "525 time: 0:13:47.075693\n",
      "526 time: 0:13:48.637608\n",
      "527 time: 0:13:50.185337\n",
      "528 time: 0:13:51.757748\n",
      "529 time: 0:13:53.305147\n",
      "530 time: 0:13:54.856032\n",
      "531 time: 0:13:56.429584\n",
      "532 time: 0:13:57.993446\n",
      "533 time: 0:13:59.554550\n",
      "534 time: 0:14:01.117125\n",
      "535 time: 0:14:02.679923\n",
      "536 time: 0:14:04.236299\n",
      "537 time: 0:14:05.791221\n",
      "538 time: 0:14:07.349723\n",
      "539 time: 0:14:08.906329\n",
      "540 time: 0:14:10.464703\n",
      "541 time: 0:14:12.024734\n",
      "542 time: 0:14:13.579230\n",
      "543 time: 0:14:15.136566\n",
      "544 time: 0:14:16.692689\n",
      "545 time: 0:14:18.246049\n",
      "546 time: 0:14:19.802825\n",
      "547 time: 0:14:21.366320\n",
      "548 time: 0:14:22.910878\n",
      "549 time: 0:14:24.462672\n",
      "550 time: 0:14:26.020163\n",
      "551 time: 0:14:28.460782\n",
      "552 time: 0:14:30.013535\n",
      "553 time: 0:14:31.578180\n",
      "554 time: 0:14:33.136422\n",
      "555 time: 0:14:34.694484\n",
      "556 time: 0:14:36.263371\n",
      "557 time: 0:14:37.817594\n",
      "558 time: 0:14:39.371216\n",
      "559 time: 0:14:40.929584\n",
      "560 time: 0:14:42.493747\n",
      "561 time: 0:14:44.058534\n",
      "562 time: 0:14:45.618634\n",
      "563 time: 0:14:47.179328\n",
      "564 time: 0:14:48.729057\n",
      "565 time: 0:14:50.292094\n",
      "566 time: 0:14:51.845969\n",
      "567 time: 0:14:53.398646\n",
      "568 time: 0:14:54.951018\n",
      "569 time: 0:14:56.508469\n",
      "570 time: 0:14:58.076839\n",
      "571 time: 0:14:59.660741\n",
      "572 time: 0:15:01.246369\n",
      "573 time: 0:15:02.804638\n",
      "574 time: 0:15:04.370313\n",
      "575 time: 0:15:05.943551\n",
      "576 time: 0:15:07.507829\n",
      "577 time: 0:15:09.114403\n",
      "578 time: 0:15:10.702097\n",
      "579 time: 0:15:12.275788\n",
      "580 time: 0:15:13.843670\n",
      "581 time: 0:15:15.417948\n",
      "582 time: 0:15:17.027923\n",
      "583 time: 0:15:18.607829\n",
      "584 time: 0:15:20.186049\n",
      "585 time: 0:15:21.772345\n",
      "586 time: 0:15:23.347661\n",
      "587 time: 0:15:24.910260\n",
      "588 time: 0:15:26.480779\n",
      "589 time: 0:15:28.041527\n",
      "590 time: 0:15:29.601419\n",
      "591 time: 0:15:31.162793\n",
      "592 time: 0:15:32.731135\n",
      "593 time: 0:15:34.292916\n",
      "594 time: 0:15:35.861237\n",
      "595 time: 0:15:37.418018\n",
      "596 time: 0:15:38.973607\n",
      "597 time: 0:15:40.535530\n",
      "598 time: 0:15:42.095253\n",
      "599 time: 0:15:43.645362\n",
      "600 time: 0:15:45.216219\n",
      "601 time: 0:15:47.632794\n",
      "602 time: 0:15:49.205907\n",
      "603 time: 0:15:50.765144\n",
      "604 time: 0:15:52.332442\n",
      "605 time: 0:15:53.886368\n",
      "606 time: 0:15:55.449455\n",
      "607 time: 0:15:57.014761\n",
      "608 time: 0:15:58.579725\n",
      "609 time: 0:16:00.140594\n",
      "610 time: 0:16:01.692268\n",
      "611 time: 0:16:03.246321\n",
      "612 time: 0:16:04.818232\n",
      "613 time: 0:16:06.373504\n",
      "614 time: 0:16:07.928205\n",
      "615 time: 0:16:09.477147\n",
      "616 time: 0:16:11.028654\n",
      "617 time: 0:16:12.586616\n",
      "618 time: 0:16:14.135910\n",
      "619 time: 0:16:15.684801\n",
      "620 time: 0:16:17.238261\n",
      "621 time: 0:16:18.791272\n",
      "622 time: 0:16:20.348151\n",
      "623 time: 0:16:21.899492\n",
      "624 time: 0:16:23.464630\n",
      "625 time: 0:16:25.039952\n",
      "626 time: 0:16:26.605678\n",
      "627 time: 0:16:28.163736\n",
      "628 time: 0:16:29.727016\n",
      "629 time: 0:16:31.286678\n",
      "630 time: 0:16:32.839834\n",
      "631 time: 0:16:34.419255\n",
      "632 time: 0:16:35.980981\n",
      "633 time: 0:16:37.542635\n",
      "634 time: 0:16:39.096329\n",
      "635 time: 0:16:40.654513\n",
      "636 time: 0:16:42.213028\n",
      "637 time: 0:16:43.761158\n",
      "638 time: 0:16:45.323762\n",
      "639 time: 0:16:46.881127\n",
      "640 time: 0:16:48.432720\n",
      "641 time: 0:16:49.989040\n",
      "642 time: 0:16:51.537306\n",
      "643 time: 0:16:53.098048\n",
      "644 time: 0:16:54.661744\n",
      "645 time: 0:16:56.233733\n",
      "646 time: 0:16:57.799762\n",
      "647 time: 0:16:59.367666\n",
      "648 time: 0:17:00.928756\n",
      "649 time: 0:17:02.507171\n",
      "650 time: 0:17:04.075839\n",
      "651 time: 0:17:06.508645\n",
      "652 time: 0:17:08.096655\n",
      "653 time: 0:17:09.663366\n",
      "654 time: 0:17:11.227224\n",
      "655 time: 0:17:12.797877\n",
      "656 time: 0:17:14.362316\n",
      "657 time: 0:17:15.927475\n",
      "658 time: 0:17:17.488780\n",
      "659 time: 0:17:19.055081\n",
      "660 time: 0:17:20.618183\n",
      "661 time: 0:17:22.184741\n",
      "662 time: 0:17:23.747564\n",
      "663 time: 0:17:25.326916\n",
      "664 time: 0:17:26.889863\n",
      "665 time: 0:17:28.446324\n",
      "666 time: 0:17:30.009131\n",
      "667 time: 0:17:31.577751\n",
      "668 time: 0:17:33.143083\n",
      "669 time: 0:17:34.698772\n",
      "670 time: 0:17:36.260124\n",
      "671 time: 0:17:37.813315\n",
      "672 time: 0:17:39.369690\n",
      "673 time: 0:17:40.939687\n",
      "674 time: 0:17:42.514709\n",
      "675 time: 0:17:44.069994\n",
      "676 time: 0:17:45.624694\n",
      "677 time: 0:17:47.200756\n",
      "678 time: 0:17:48.758210\n",
      "679 time: 0:17:50.318820\n",
      "680 time: 0:17:51.877594\n",
      "681 time: 0:17:53.423096\n",
      "682 time: 0:17:54.979677\n",
      "683 time: 0:17:56.556904\n",
      "684 time: 0:17:58.116432\n",
      "685 time: 0:17:59.671260\n",
      "686 time: 0:18:01.231333\n",
      "687 time: 0:18:02.803763\n",
      "688 time: 0:18:04.363747\n",
      "689 time: 0:18:05.918023\n",
      "690 time: 0:18:07.477184\n",
      "691 time: 0:18:09.031529\n",
      "692 time: 0:18:10.588456\n",
      "693 time: 0:18:12.152844\n",
      "694 time: 0:18:13.707632\n",
      "695 time: 0:18:15.261114\n",
      "696 time: 0:18:16.821161\n",
      "697 time: 0:18:18.396020\n",
      "698 time: 0:18:19.980342\n",
      "699 time: 0:18:21.556597\n",
      "700 time: 0:18:23.119573\n",
      "701 time: 0:18:25.549388\n",
      "702 time: 0:18:27.114102\n",
      "703 time: 0:18:28.692105\n",
      "704 time: 0:18:30.251747\n",
      "705 time: 0:18:31.819444\n",
      "706 time: 0:18:33.385254\n",
      "707 time: 0:18:34.939711\n",
      "708 time: 0:18:36.498788\n",
      "709 time: 0:18:38.057818\n",
      "710 time: 0:18:39.606327\n",
      "711 time: 0:18:41.167317\n",
      "712 time: 0:18:42.719311\n",
      "713 time: 0:18:44.276766\n",
      "714 time: 0:18:45.838699\n",
      "715 time: 0:18:47.412695\n",
      "716 time: 0:18:48.967484\n",
      "717 time: 0:18:50.525028\n",
      "718 time: 0:18:52.080981\n",
      "719 time: 0:18:53.694423\n",
      "720 time: 0:18:55.298987\n",
      "721 time: 0:18:56.918647\n",
      "722 time: 0:18:58.543293\n",
      "723 time: 0:19:00.149234\n",
      "724 time: 0:19:01.762132\n",
      "725 time: 0:19:03.319628\n",
      "726 time: 0:19:04.875623\n",
      "727 time: 0:19:06.439584\n",
      "728 time: 0:19:08.032548\n",
      "729 time: 0:19:09.626929\n",
      "730 time: 0:19:11.236530\n",
      "731 time: 0:19:12.857011\n",
      "732 time: 0:19:14.467998\n",
      "733 time: 0:19:16.097397\n",
      "734 time: 0:19:17.709650\n",
      "735 time: 0:19:19.319147\n",
      "736 time: 0:19:20.949128\n",
      "737 time: 0:19:22.514338\n",
      "738 time: 0:19:23.998226\n",
      "739 time: 0:19:25.492290\n",
      "740 time: 0:19:27.086021\n",
      "741 time: 0:19:28.644148\n",
      "742 time: 0:19:30.174890\n",
      "743 time: 0:19:31.682588\n",
      "744 time: 0:19:33.217027\n",
      "745 time: 0:19:34.729945\n",
      "746 time: 0:19:36.262357\n",
      "747 time: 0:19:37.781273\n",
      "748 time: 0:19:39.268796\n",
      "749 time: 0:19:40.748862\n",
      "750 time: 0:19:42.231424\n",
      "751 time: 0:19:44.550065\n",
      "752 time: 0:19:46.033111\n",
      "753 time: 0:19:47.529262\n",
      "754 time: 0:19:49.029301\n",
      "755 time: 0:19:50.511118\n",
      "756 time: 0:19:51.996175\n",
      "757 time: 0:19:53.477694\n",
      "758 time: 0:19:54.960637\n",
      "759 time: 0:19:56.444336\n",
      "760 time: 0:19:57.940405\n",
      "761 time: 0:19:59.425494\n",
      "762 time: 0:20:00.904556\n",
      "763 time: 0:20:02.387236\n",
      "764 time: 0:20:03.873083\n",
      "765 time: 0:20:05.379626\n",
      "766 time: 0:20:06.869166\n",
      "767 time: 0:20:08.351525\n",
      "768 time: 0:20:09.837514\n",
      "769 time: 0:20:11.316292\n",
      "770 time: 0:20:12.792639\n",
      "771 time: 0:20:14.275023\n",
      "772 time: 0:20:15.761139\n",
      "773 time: 0:20:17.251737\n",
      "774 time: 0:20:18.738720\n",
      "775 time: 0:20:20.231716\n",
      "776 time: 0:20:21.709764\n",
      "777 time: 0:20:23.189084\n",
      "778 time: 0:20:24.670042\n",
      "779 time: 0:20:26.152764\n",
      "780 time: 0:20:27.641911\n",
      "781 time: 0:20:29.121996\n",
      "782 time: 0:20:30.602038\n",
      "783 time: 0:20:32.081649\n",
      "784 time: 0:20:33.557820\n",
      "785 time: 0:20:35.057906\n",
      "786 time: 0:20:36.556898\n",
      "787 time: 0:20:38.064549\n",
      "788 time: 0:20:39.566559\n",
      "789 time: 0:20:41.045639\n",
      "790 time: 0:20:42.521270\n",
      "791 time: 0:20:44.000818\n",
      "792 time: 0:20:45.478865\n",
      "793 time: 0:20:46.963836\n",
      "794 time: 0:20:48.440887\n",
      "795 time: 0:20:49.923442\n",
      "796 time: 0:20:51.409795\n",
      "797 time: 0:20:52.899555\n",
      "798 time: 0:20:54.384366\n",
      "799 time: 0:20:55.867417\n",
      "800 time: 0:20:57.349478\n",
      "801 time: 0:20:59.641834\n",
      "802 time: 0:21:01.129052\n",
      "803 time: 0:21:02.617101\n",
      "804 time: 0:21:04.102644\n",
      "805 time: 0:21:05.584823\n",
      "806 time: 0:21:07.075434\n",
      "807 time: 0:21:08.573428\n",
      "808 time: 0:21:10.067311\n",
      "809 time: 0:21:11.552343\n",
      "810 time: 0:21:13.036643\n",
      "811 time: 0:21:14.518682\n",
      "812 time: 0:21:16.005798\n",
      "813 time: 0:21:17.498273\n",
      "814 time: 0:21:18.982966\n",
      "815 time: 0:21:20.483811\n",
      "816 time: 0:21:21.972405\n",
      "817 time: 0:21:23.462049\n",
      "818 time: 0:21:24.964538\n",
      "819 time: 0:21:26.455634\n",
      "820 time: 0:21:27.945505\n",
      "821 time: 0:21:29.432832\n",
      "822 time: 0:21:30.947495\n",
      "823 time: 0:21:32.464440\n",
      "824 time: 0:21:33.949775\n",
      "825 time: 0:21:35.434844\n",
      "826 time: 0:21:36.921018\n",
      "827 time: 0:21:38.407588\n",
      "828 time: 0:21:39.898572\n",
      "829 time: 0:21:41.394684\n",
      "830 time: 0:21:42.886742\n",
      "831 time: 0:21:44.369113\n",
      "832 time: 0:21:45.848215\n",
      "833 time: 0:21:47.348347\n",
      "834 time: 0:21:48.835766\n",
      "835 time: 0:21:50.323767\n",
      "836 time: 0:21:51.856693\n",
      "837 time: 0:21:53.344361\n",
      "838 time: 0:21:54.820520\n",
      "839 time: 0:21:56.318902\n",
      "840 time: 0:21:57.806392\n",
      "841 time: 0:21:59.292476\n",
      "842 time: 0:22:00.778299\n",
      "843 time: 0:22:02.266774\n",
      "844 time: 0:22:03.753307\n",
      "845 time: 0:22:05.233399\n",
      "846 time: 0:22:06.721682\n",
      "847 time: 0:22:08.211256\n",
      "848 time: 0:22:09.696315\n",
      "849 time: 0:22:11.183009\n",
      "850 time: 0:22:12.684965\n",
      "851 time: 0:22:14.974954\n",
      "852 time: 0:22:16.458084\n",
      "853 time: 0:22:17.950824\n",
      "854 time: 0:22:19.432511\n",
      "855 time: 0:22:20.909581\n",
      "856 time: 0:22:22.389923\n",
      "857 time: 0:22:23.869770\n",
      "858 time: 0:22:25.349934\n",
      "859 time: 0:22:26.834135\n",
      "860 time: 0:22:28.334124\n",
      "861 time: 0:22:29.813695\n",
      "862 time: 0:22:31.297229\n",
      "863 time: 0:22:32.777939\n",
      "864 time: 0:22:34.259954\n",
      "865 time: 0:22:35.741360\n",
      "866 time: 0:22:37.225400\n",
      "867 time: 0:22:38.707461\n",
      "868 time: 0:22:40.196457\n",
      "869 time: 0:22:41.683558\n",
      "870 time: 0:22:43.165855\n",
      "871 time: 0:22:44.666886\n",
      "872 time: 0:22:46.155592\n",
      "873 time: 0:22:47.637957\n",
      "874 time: 0:22:49.121921\n",
      "875 time: 0:22:50.609929\n",
      "876 time: 0:22:52.094267\n",
      "877 time: 0:22:53.578808\n",
      "878 time: 0:22:55.063964\n",
      "879 time: 0:22:56.553447\n",
      "880 time: 0:22:58.043092\n",
      "881 time: 0:22:59.530238\n",
      "882 time: 0:23:01.025108\n",
      "883 time: 0:23:02.509246\n",
      "884 time: 0:23:03.991072\n",
      "885 time: 0:23:05.471145\n",
      "886 time: 0:23:06.981102\n",
      "887 time: 0:23:08.562851\n",
      "888 time: 0:23:10.065325\n",
      "889 time: 0:23:11.551199\n",
      "890 time: 0:23:13.048307\n",
      "891 time: 0:23:14.535384\n",
      "892 time: 0:23:16.028621\n",
      "893 time: 0:23:17.517641\n",
      "894 time: 0:23:19.003345\n",
      "895 time: 0:23:20.488231\n",
      "896 time: 0:23:21.971142\n",
      "897 time: 0:23:23.458448\n",
      "898 time: 0:23:24.948201\n",
      "899 time: 0:23:26.435248\n",
      "900 time: 0:23:27.918251\n",
      "901 time: 0:23:30.209871\n",
      "902 time: 0:23:31.692269\n",
      "903 time: 0:23:33.194797\n",
      "904 time: 0:23:34.681197\n",
      "905 time: 0:23:36.164755\n",
      "906 time: 0:23:37.659678\n",
      "907 time: 0:23:39.146941\n",
      "908 time: 0:23:40.638952\n",
      "909 time: 0:23:42.130978\n",
      "910 time: 0:23:43.617452\n",
      "911 time: 0:23:45.103363\n",
      "912 time: 0:23:46.598899\n",
      "913 time: 0:23:48.087918\n",
      "914 time: 0:23:49.574169\n",
      "915 time: 0:23:51.060352\n",
      "916 time: 0:23:52.542782\n",
      "917 time: 0:23:54.031395\n",
      "918 time: 0:23:55.514413\n",
      "919 time: 0:23:57.000889\n",
      "920 time: 0:23:58.495619\n",
      "921 time: 0:23:59.978690\n",
      "922 time: 0:24:01.468735\n",
      "923 time: 0:24:02.951285\n",
      "924 time: 0:24:04.446838\n",
      "925 time: 0:24:05.936918\n",
      "926 time: 0:24:07.427908\n",
      "927 time: 0:24:08.912939\n",
      "928 time: 0:24:10.397299\n",
      "929 time: 0:24:11.887122\n",
      "930 time: 0:24:13.371719\n",
      "931 time: 0:24:14.858852\n",
      "932 time: 0:24:16.351133\n",
      "933 time: 0:24:17.843713\n",
      "934 time: 0:24:19.329335\n",
      "935 time: 0:24:20.823396\n",
      "936 time: 0:24:22.311418\n",
      "937 time: 0:24:23.796522\n",
      "938 time: 0:24:25.277798\n",
      "939 time: 0:24:26.763384\n",
      "940 time: 0:24:28.243532\n",
      "941 time: 0:24:29.722865\n",
      "942 time: 0:24:31.208225\n",
      "943 time: 0:24:32.690323\n",
      "944 time: 0:24:34.177302\n",
      "945 time: 0:24:35.657376\n",
      "946 time: 0:24:37.163378\n",
      "947 time: 0:24:38.652385\n",
      "948 time: 0:24:40.139614\n",
      "949 time: 0:24:41.623852\n",
      "950 time: 0:24:43.116611\n",
      "951 time: 0:24:45.404198\n",
      "952 time: 0:24:46.895689\n",
      "953 time: 0:24:48.381577\n",
      "954 time: 0:24:49.865615\n",
      "955 time: 0:24:51.352318\n",
      "956 time: 0:24:52.870468\n",
      "957 time: 0:24:54.371043\n",
      "958 time: 0:24:55.863163\n",
      "959 time: 0:24:57.344359\n",
      "960 time: 0:24:58.825538\n",
      "961 time: 0:25:00.307790\n",
      "962 time: 0:25:01.793595\n",
      "963 time: 0:25:03.287997\n",
      "964 time: 0:25:04.771152\n",
      "965 time: 0:25:06.259194\n",
      "966 time: 0:25:07.748545\n",
      "967 time: 0:25:09.240776\n",
      "968 time: 0:25:10.729448\n",
      "969 time: 0:25:12.210489\n",
      "970 time: 0:25:13.694522\n",
      "971 time: 0:25:15.181013\n",
      "972 time: 0:25:16.661361\n",
      "973 time: 0:25:18.151342\n",
      "974 time: 0:25:19.637599\n",
      "975 time: 0:25:21.117257\n",
      "976 time: 0:25:22.600258\n",
      "977 time: 0:25:24.093897\n",
      "978 time: 0:25:25.580941\n",
      "979 time: 0:25:27.064125\n",
      "980 time: 0:25:28.552445\n",
      "981 time: 0:25:30.044797\n",
      "982 time: 0:25:31.529401\n",
      "983 time: 0:25:33.012936\n",
      "984 time: 0:25:34.497357\n",
      "985 time: 0:25:35.982972\n",
      "986 time: 0:25:37.465547\n",
      "987 time: 0:25:38.950599\n",
      "988 time: 0:25:40.450589\n",
      "989 time: 0:25:41.933609\n",
      "990 time: 0:25:43.423385\n",
      "991 time: 0:25:44.909719\n",
      "992 time: 0:25:46.403764\n",
      "993 time: 0:25:47.894428\n",
      "994 time: 0:25:49.378836\n",
      "995 time: 0:25:50.854833\n",
      "996 time: 0:25:52.344224\n",
      "997 time: 0:25:53.848613\n",
      "998 time: 0:25:55.334748\n",
      "999 time: 0:25:56.829393\n",
      "1000 time: 0:25:58.319127\n",
      "1001 time: 0:26:00.610541\n",
      "1002 time: 0:26:02.102554\n",
      "1003 time: 0:26:03.589670\n",
      "1004 time: 0:26:05.071312\n",
      "1005 time: 0:26:06.561718\n",
      "1006 time: 0:26:08.055528\n",
      "1007 time: 0:26:09.538582\n",
      "1008 time: 0:26:11.022796\n",
      "1009 time: 0:26:12.518214\n",
      "1010 time: 0:26:14.008072\n",
      "1011 time: 0:26:15.490847\n",
      "1012 time: 0:26:16.978864\n",
      "1013 time: 0:26:18.469036\n",
      "1014 time: 0:26:19.952150\n",
      "1015 time: 0:26:21.435244\n",
      "1016 time: 0:26:22.920203\n",
      "1017 time: 0:26:24.427174\n",
      "1018 time: 0:26:25.912222\n",
      "1019 time: 0:26:27.397925\n",
      "1020 time: 0:26:28.884249\n",
      "1021 time: 0:26:30.366738\n",
      "1022 time: 0:26:31.846757\n",
      "1023 time: 0:26:33.325096\n",
      "1024 time: 0:26:34.806705\n",
      "1025 time: 0:26:36.289745\n",
      "1026 time: 0:26:37.778934\n",
      "1027 time: 0:26:39.266773\n",
      "1028 time: 0:26:40.755846\n",
      "1029 time: 0:26:42.239170\n",
      "1030 time: 0:26:43.729039\n",
      "1031 time: 0:26:45.224262\n",
      "1032 time: 0:26:46.708055\n",
      "1033 time: 0:26:48.197932\n",
      "1034 time: 0:26:49.681024\n",
      "1035 time: 0:26:51.170190\n",
      "1036 time: 0:26:52.649976\n",
      "1037 time: 0:26:54.134038\n",
      "1038 time: 0:26:55.617483\n",
      "1039 time: 0:26:57.104601\n",
      "1040 time: 0:26:58.601417\n",
      "1041 time: 0:27:00.087466\n",
      "1042 time: 0:27:01.578470\n",
      "1043 time: 0:27:03.062400\n",
      "1044 time: 0:27:04.542767\n",
      "1045 time: 0:27:06.032579\n",
      "1046 time: 0:27:07.519658\n",
      "1047 time: 0:27:09.003801\n",
      "1048 time: 0:27:10.489827\n",
      "1049 time: 0:27:11.974981\n",
      "1050 time: 0:27:13.461404\n",
      "1051 time: 0:27:15.756571\n",
      "1052 time: 0:27:17.259904\n",
      "1053 time: 0:27:18.759145\n",
      "1054 time: 0:27:20.244373\n",
      "1055 time: 0:27:21.727399\n",
      "1056 time: 0:27:23.211431\n",
      "1057 time: 0:27:24.697179\n",
      "1058 time: 0:27:26.182634\n",
      "1059 time: 0:27:27.674887\n",
      "1060 time: 0:27:29.165271\n",
      "1061 time: 0:27:30.648941\n",
      "1062 time: 0:27:32.147867\n",
      "1063 time: 0:27:33.630840\n",
      "1064 time: 0:27:35.117945\n",
      "1065 time: 0:27:36.601354\n",
      "1066 time: 0:27:38.090454\n",
      "1067 time: 0:27:39.572905\n",
      "1068 time: 0:27:41.056982\n",
      "1069 time: 0:27:42.534268\n",
      "1070 time: 0:27:44.023571\n",
      "1071 time: 0:27:45.507389\n"
     ]
    }
   ],
   "source": [
    "#! rm -rf ./samples\n",
    "epochs=30000\n",
    "batch_size=1\n",
    "sample_interval=50\n",
    "start_time = datetime.datetime.now()\n",
    "for epoch in range(epochs+1):\n",
    "  # calculate output shape of D (PatchGAN)\n",
    "  patch = int(width / 2**4)\n",
    "  disc_patch = (patch, patch, 1)\n",
    "  # ----------------------\n",
    "  #  Train Discriminator\n",
    "  # ----------------------\n",
    "\n",
    "  # Sample images and their conditioning counterparts\n",
    "  imgs_hr, imgs_lr = data_loader.load_data(batch_size)\n",
    "\n",
    "  # From low res. image generate high res. version\n",
    "  fake_hr = generator.predict(imgs_lr)\n",
    "\n",
    "  valid = np.ones((batch_size,) + disc_patch)\n",
    "  fake = np.zeros((batch_size,) + disc_patch)\n",
    "\n",
    "  # Train the discriminators (original images = real / generated = Fake)\n",
    "  d_loss_real = discriminator.train_on_batch(imgs_hr, valid)\n",
    "  d_loss_fake = discriminator.train_on_batch(fake_hr, fake)\n",
    "  d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "  # ------------------\n",
    "  #  Train Generator\n",
    "  # ------------------\n",
    "\n",
    "  # Sample images and their conditioning counterparts\n",
    "  imgs_hr, imgs_lr = data_loader.load_data(batch_size)\n",
    "\n",
    "  # The generators want the discriminators to label the generated images as real\n",
    "  valid = np.ones((batch_size,) + disc_patch)\n",
    "\n",
    "  # Extract ground truth image features using pre-trained VGG19 model\n",
    "  image_features = feature_loss.predict(imgs_hr)\n",
    "\n",
    "  # Train the generators\n",
    "  g_loss = gan.train_on_batch([imgs_lr], [valid, image_features])\n",
    "\n",
    "  elapsed_time = datetime.datetime.now() - start_time\n",
    "  # Plot the progress\n",
    "  print (\"%d time: %s\" % (epoch, elapsed_time))\n",
    "\n",
    "  # If at save interval => save generated image samples\n",
    "  if epoch % sample_interval == 0:\n",
    "      sample_images(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l576mANkDFzK"
   },
   "outputs": [],
   "source": [
    "save_generator = keras.Sequential([generator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvvPaO-wFC9T"
   },
   "outputs": [],
   "source": [
    "save_generator.add(Lambda(lambda x: (x + 1) * 127.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_DQC9aKuZ9-"
   },
   "source": [
    "## Convert to CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gCiDYRwwvczg"
   },
   "outputs": [],
   "source": [
    "save_generator.save('generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting coremltools==3.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/bf/ae44737a06c21e64b6e950bc6da4652c3127656daeec95994210c23826c4/coremltools-3.2-cp37-none-macosx_10_15_intel.whl (4.0MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0MB 686kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /opt/anaconda3/lib/python3.7/site-packages (from coremltools==3.2) (1.17.2)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /opt/anaconda3/lib/python3.7/site-packages (from coremltools==3.2) (3.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/anaconda3/lib/python3.7/site-packages (from coremltools==3.2) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from protobuf>=3.1.0->coremltools==3.2) (41.4.0)\n",
      "Installing collected packages: coremltools\n",
      "  Found existing installation: coremltools 3.4\n",
      "    Uninstalling coremltools-3.4:\n",
      "      Successfully uninstalled coremltools-3.4\n",
      "Successfully installed coremltools-3.2\n"
     ]
    }
   ],
   "source": [
    "! pip install coremltools==3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wrNl1_mXufuw",
    "outputId": "d2a684c5-a5f1-4217-f595-13dc84d6db2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.2.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 158kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.17.2)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.1.0)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (5.1.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.0.8)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.2.4\n",
      "Collecting tensorflow==1.14.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/11/037887c5cbac5af3124050fb6348e67caa038734cc9673b11c31c8939072/tensorflow-1.14.0-cp37-cp37m-macosx_10_11_x86_64.whl (105.8MB)\n",
      "\u001b[K     |████████████████████████████████| 105.8MB 263kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0 (from tensorflow==1.14.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 10.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.17.2)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow==1.14.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "\u001b[K     |████████████████████████████████| 491kB 2.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.33.6)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (3.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.9.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.7.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.2.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.11.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.23.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (41.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/anaconda3/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.16.0)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.9.0)\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
      "  Found existing installation: tensorboard 2.0.0\n",
      "    Uninstalling tensorboard-2.0.0:\n",
      "      Successfully uninstalled tensorboard-2.0.0\n",
      "  Found existing installation: tensorflow-estimator 2.0.0\n",
      "    Uninstalling tensorflow-estimator-2.0.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.0.0\n",
      "  Found existing installation: tensorflow 2.0.0\n",
      "    Uninstalling tensorflow-2.0.0:\n",
      "      Successfully uninstalled tensorflow-2.0.0\n",
      "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
     ]
    }
   ],
   "source": [
    "! pip install keras==2.2.4\n",
    "! pip install tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "4cqRZufbFuD8",
    "outputId": "80289a90-2ca4-449b-d0ad-cbf1fa998e96"
   },
   "outputs": [],
   "source": [
    "from coremltools.proto import NeuralNetwork_pb2\n",
    "\n",
    "def convert_lambda(layer):\n",
    "    params = NeuralNetwork_pb2.CustomLayerParams()\n",
    "\n",
    "    # The name of the Swift or Obj-C class that implements this layer.\n",
    "    params.className = \"Lambda\"\n",
    "\n",
    "    # The desciption is shown in Xcode's mlmodel viewer.\n",
    "    params.description = \"Post process\"\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.4 (default, Aug 13 2019, 15:17:50) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)] :: Anaconda, Inc. on darwin\n",
      "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
      ">>> "
     ]
    }
   ],
   "source": [
    "! python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xKfEzd8KdGYO",
    "outputId": "fe393777-b751-4722-9481-8b88e54ca1ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : model_12_input, <keras.engine.input_layer.InputLayer object at 0x1a3e0f41d0>\n",
      "1 : model_12_conv2d_73, <keras.layers.convolutional.Conv2D object at 0x1a2ebbd6d0>\n",
      "2 : model_12_conv2d_73__activation__, <keras.layers.core.Activation object at 0x1a38518290>\n",
      "3 : model_12_conv2d_74, <keras.layers.convolutional.Conv2D object at 0x1a2ebbd610>\n",
      "4 : model_12_conv2d_74__activation__, <keras.layers.core.Activation object at 0x1a385183d0>\n",
      "5 : model_12_max_pooling2d_9, <keras.layers.pooling.MaxPooling2D object at 0x106aaf490>\n",
      "6 : model_12_conv2d_75, <keras.layers.convolutional.Conv2D object at 0x106aaf290>\n",
      "7 : model_12_conv2d_75__activation__, <keras.layers.core.Activation object at 0x1a38744190>\n",
      "8 : model_12_conv2d_76, <keras.layers.convolutional.Conv2D object at 0x106aaf150>\n",
      "9 : model_12_conv2d_76__activation__, <keras.layers.core.Activation object at 0x1a38744750>\n",
      "10 : model_12_max_pooling2d_10, <keras.layers.pooling.MaxPooling2D object at 0x1a2ec909d0>\n",
      "11 : model_12_conv2d_77, <keras.layers.convolutional.Conv2D object at 0x106c98910>\n",
      "12 : model_12_conv2d_77__activation__, <keras.layers.core.Activation object at 0x1a38744610>\n",
      "13 : model_12_conv2d_78, <keras.layers.convolutional.Conv2D object at 0x1a3e0f43d0>\n",
      "14 : model_12_conv2d_78__activation__, <keras.layers.core.Activation object at 0x1a38744910>\n",
      "15 : model_12_max_pooling2d_11, <keras.layers.pooling.MaxPooling2D object at 0x1a3e0f4350>\n",
      "16 : model_12_conv2d_79, <keras.layers.convolutional.Conv2D object at 0x1a3e0f4710>\n",
      "17 : model_12_conv2d_79__activation__, <keras.layers.core.Activation object at 0x1a38744a10>\n",
      "18 : model_12_conv2d_80, <keras.layers.convolutional.Conv2D object at 0x1a3e0f4890>\n",
      "19 : model_12_conv2d_80__activation__, <keras.layers.core.Activation object at 0x1a38744a90>\n",
      "20 : model_12_max_pooling2d_12, <keras.layers.pooling.MaxPooling2D object at 0x1a3e0f4c10>\n",
      "21 : model_12_conv2d_81, <keras.layers.convolutional.Conv2D object at 0x1a3e0f4c90>\n",
      "22 : model_12_conv2d_81__activation__, <keras.layers.core.Activation object at 0x1a38744b10>\n",
      "23 : model_12_conv2d_82, <keras.layers.convolutional.Conv2D object at 0x1a3e0f4d90>\n",
      "24 : model_12_conv2d_82__activation__, <keras.layers.core.Activation object at 0x1a38744b90>\n",
      "25 : model_12_up_sampling2d_9, <keras.layers.convolutional.UpSampling2D object at 0x1a38b29190>\n",
      "26 : model_12_conv2d_83, <keras.layers.convolutional.Conv2D object at 0x1a38b29110>\n",
      "27 : model_12_conv2d_83__activation__, <keras.layers.core.Activation object at 0x1a38744c10>\n",
      "28 : model_12_concatenate_9, <keras.layers.merge.Concatenate object at 0x1a2eb89fd0>\n",
      "29 : model_12_conv2d_84, <keras.layers.convolutional.Conv2D object at 0x1a2ebbd050>\n",
      "30 : model_12_conv2d_84__activation__, <keras.layers.core.Activation object at 0x1a38744c90>\n",
      "31 : model_12_conv2d_85, <keras.layers.convolutional.Conv2D object at 0x1a38b29450>\n",
      "32 : model_12_conv2d_85__activation__, <keras.layers.core.Activation object at 0x1a38744d10>\n",
      "33 : model_12_up_sampling2d_10, <keras.layers.convolutional.UpSampling2D object at 0x1a38b29650>\n",
      "34 : model_12_conv2d_86, <keras.layers.convolutional.Conv2D object at 0x1a38b291d0>\n",
      "35 : model_12_conv2d_86__activation__, <keras.layers.core.Activation object at 0x1a38744d90>\n",
      "36 : model_12_concatenate_10, <keras.layers.merge.Concatenate object at 0x1a38b298d0>\n",
      "37 : model_12_conv2d_87, <keras.layers.convolutional.Conv2D object at 0x1a38b29a90>\n",
      "38 : model_12_conv2d_87__activation__, <keras.layers.core.Activation object at 0x1a38744e10>\n",
      "39 : model_12_conv2d_88, <keras.layers.convolutional.Conv2D object at 0x1a38b29b10>\n",
      "40 : model_12_conv2d_88__activation__, <keras.layers.core.Activation object at 0x1a38744e90>\n",
      "41 : model_12_up_sampling2d_11, <keras.layers.convolutional.UpSampling2D object at 0x1a38b29d10>\n",
      "42 : model_12_conv2d_89, <keras.layers.convolutional.Conv2D object at 0x1a38b29a50>\n",
      "43 : model_12_conv2d_89__activation__, <keras.layers.core.Activation object at 0x1a38744f10>\n",
      "44 : model_12_concatenate_11, <keras.layers.merge.Concatenate object at 0x1a38b2f150>\n",
      "45 : model_12_conv2d_90, <keras.layers.convolutional.Conv2D object at 0x1a38b2f190>\n",
      "46 : model_12_conv2d_90__activation__, <keras.layers.core.Activation object at 0x1a38744f90>\n",
      "47 : model_12_conv2d_91, <keras.layers.convolutional.Conv2D object at 0x1a38b2f210>\n",
      "48 : model_12_conv2d_91__activation__, <keras.layers.core.Activation object at 0x1a386f3e90>\n",
      "49 : model_12_up_sampling2d_12, <keras.layers.convolutional.UpSampling2D object at 0x1a38b2f410>\n",
      "50 : model_12_conv2d_92, <keras.layers.convolutional.Conv2D object at 0x1a38b2f110>\n",
      "51 : model_12_conv2d_92__activation__, <keras.layers.core.Activation object at 0x1a385dc9d0>\n",
      "52 : model_12_concatenate_12, <keras.layers.merge.Concatenate object at 0x1a38b2f690>\n",
      "53 : model_12_conv2d_93, <keras.layers.convolutional.Conv2D object at 0x106ab4290>\n",
      "54 : model_12_conv2d_93__activation__, <keras.layers.core.Activation object at 0x1a3e0f4190>\n",
      "55 : model_12_conv2d_94, <keras.layers.convolutional.Conv2D object at 0x1a38b2f8d0>\n",
      "56 : model_12_conv2d_94__activation__, <keras.layers.core.Activation object at 0x1a2ec90a90>\n",
      "57 : model_12_conv2d_95, <keras.layers.convolutional.Conv2D object at 0x1a38b2fad0>\n",
      "58 : model_12_conv2d_95__activation__, <keras.layers.core.Activation object at 0x1a2ec8bdd0>\n",
      "59 : model_12_conv2d_96, <keras.layers.convolutional.Conv2D object at 0x1a38b2fcd0>\n",
      "60 : model_12_conv2d_96__activation__, <keras.layers.core.Activation object at 0x1a2ec8be50>\n",
      "61 : lambda_63, <keras.layers.core.Lambda object at 0x1a386a5fd0>\n"
     ]
    }
   ],
   "source": [
    "import coremltools\n",
    "coreml_model = coremltools.converters.keras.convert('generator512_14.h5', input_names='input', output_names='output', image_input_names='input', add_custom_layers=True, image_scale=2/255, gray_bias=-1, red_bias=-1, custom_conversion_functions={ \"Lambda\": convert_lambda }, use_float_arraytype=True)\n",
    "\n",
    "# Saving the Core ML model to a file.\n",
    "coreml_model.save('colorizer.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lvRkAU67GlYH"
   },
   "outputs": [],
   "source": [
    "import coremltools\n",
    "import coremltools.proto.FeatureTypes_pb2 as ft \n",
    "\n",
    "spec = coremltools.utils.load_spec(\"colorizer.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OGM09r11GoUF"
   },
   "outputs": [],
   "source": [
    "output = spec.description.output[0]\n",
    "width = 512\n",
    "import coremltools.proto.FeatureTypes_pb2 as ft\n",
    "output.type.imageType.colorSpace = ft.ImageFeatureType.RGB\n",
    "output.type.imageType.height = width\n",
    "output.type.imageType.width = width\n",
    "\n",
    "coremltools.utils.save_spec(spec, \"Colorizer.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WfV0PXb1Hohb",
    "outputId": "7f5cde37-668d-45b5-95c2-bb682c549f72"
   },
   "outputs": [],
   "source": [
    "#! pip uninstall keras\n",
    "#! pip uninstall tensorflow\n",
    "! pip install tensorflow\n",
    "! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y77D0L9BX7pw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "keras colorizer",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
