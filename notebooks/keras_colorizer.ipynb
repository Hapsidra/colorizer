{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "brKY4zEccKnZ"
   },
   "source": [
    "# Keras colorizer of CelebA using Generative Adversarial Networks.\n",
    "The dataset can be downloaded from: https://www.dropbox.com/sh/8oqt9vytwxb3s4r/AADIKlz8PR9zr6Y20qbkunrba/Img/img_align_celeba.zip?dl=0\n",
    "## Instrustion on running the script:\n",
    "1. Download the dataset from the provided link\n",
    "2. Save the folder 'img_align_celeba' to 'datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "hvSFlk6kVhko",
    "outputId": "74539bf7-76bc-4b9f-891b-6f82bed2d22c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wHjTCYzJNvFZ"
   },
   "outputs": [],
   "source": [
    "! mkdir datasets\n",
    "! mkdir originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gu8Jm-c8sMhe"
   },
   "outputs": [],
   "source": [
    "! unzip -q \"/content/drive/My Drive/img_align_celeba.zip\" -d datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0oNurEUNy6V"
   },
   "outputs": [],
   "source": [
    "! unzip -q \"/content/drive/My Drive/coco_val2017.zip\" -d datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Mkb1xGjOH6P"
   },
   "outputs": [],
   "source": [
    "! mv datasets/val2017/* originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5oX2UN5FQl40"
   },
   "outputs": [],
   "source": [
    "! find /content/datasets/img_align_celeba -type f -exec sh -c 'mv \"$@\" \"$0\"' originals/ {} +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pjIUDN76FDeQ",
    "outputId": "9f1b8614-7bb2-4499-a1b3-34e534776517"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add, MaxPooling2D\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.applications import VGG19\n",
    "from keras.models import Sequential, Model\n",
    "import keras\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import keras.backend as K\n",
    "import scipy.misc\n",
    "import PIL\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.applications.vgg19 import preprocess_input as vgg19_preprocess_input\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 3} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URIEcC5yHza8"
   },
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "  def __init__(self, img_res=(256, 256)):\n",
    "    self.img_res = img_res\n",
    "\n",
    "  def load_data(self, batch_size=1, is_testing=False):\n",
    "    path = glob('./originals/*')\n",
    "    batch_images = np.random.choice(path, size=batch_size)\n",
    "\n",
    "    imgs_hr = []\n",
    "    imgs_lr = []\n",
    "    for img_path in batch_images:\n",
    "      img_hr, img_lr = self._load(img_path, self.img_res)\n",
    "\n",
    "      imgs_hr.append(img_hr)\n",
    "      imgs_lr.append(img_lr)\n",
    "      \n",
    "    # нормализация данных\n",
    "    imgs_hr = np.array(imgs_hr) / 127.5 - 1\n",
    "    imgs_lr = np.array(imgs_lr) / 127.5 - 1\n",
    "\n",
    "    return imgs_hr, imgs_lr\n",
    "\n",
    "  # returns pair (original photo, grayscale photo)\n",
    "  def _load(self, path, size):\n",
    "    return np.array(PIL.Image.open(path).resize(size)).astype(np.float), np.expand_dims(np.array(PIL.Image.open(path).resize(size).convert('L')).astype(np.float), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-MMu2-hCHgAJ"
   },
   "outputs": [],
   "source": [
    "hr_channels = 3\n",
    "lr_channels = 1\n",
    "width = 512\n",
    "lr_shape = (width, width, lr_channels)\n",
    "hr_shape = (width, width, hr_channels)\n",
    "\n",
    "n_residual_blocks = 16\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "# configure data loader\n",
    "data_loader = DataLoader(img_res=(width, width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kt5tos90ZI8e"
   },
   "outputs": [],
   "source": [
    "def sample_images(epoch):\n",
    "  os.makedirs('samples', exist_ok=True)\n",
    "  r,c = 2,3\n",
    "  imgs_hr, imgs_lr = data_loader.load_data(batch_size=2, is_testing=True)\n",
    "  fake_hr = generator.predict(imgs_lr)\n",
    "  imgs_lr = 0.5 * imgs_lr + 0.5\n",
    "  fake_hr = 0.5 * fake_hr + 0.5\n",
    "  imgs_hr = 0.5 * imgs_hr + 0.5\n",
    "  titles = [\"B&W\", \"Generated\", \"Original\"]\n",
    "  fig, axs = plt.subplots(r, c)\n",
    "  cnt = 0\n",
    "  for row in range(r):\n",
    "    for col, image in enumerate([imgs_lr, fake_hr, imgs_hr]):\n",
    "      if col == 0:\n",
    "        axs[row, col].imshow(np.array(PIL.Image.fromarray((np.squeeze(image[row])*255).astype(np.uint8)).convert('RGB')))\n",
    "      else:\n",
    "        axs[row, col].imshow(image[row])\n",
    "      axs[row, col].set_title(titles[col])\n",
    "      axs[row, col].axis('off')\n",
    "    cnt += 1\n",
    "  def zerofy(s: str):\n",
    "    while len(s) < 6:\n",
    "      s = '0' + s\n",
    "    return s\n",
    "  fig.savefig('samples/'+zerofy(str(epoch)) +'.png')\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oK8xkM2TT6v_"
   },
   "source": [
    "We use a pre-trained VGG19 model to extract image features from the high resolution and the generated high resolution images and minimize the mse between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eLR8rIHUT9eT"
   },
   "outputs": [],
   "source": [
    "def build_feature_loss(input_size):\n",
    "  vgg = VGG19(weights='imagenet')\n",
    "  vgg.outputs = [vgg.layers[9].output]\n",
    "  img = Input(shape=input_size)\n",
    "  img_features = vgg(img)\n",
    "  model = Model(img, img_features)\n",
    "  model.trainable = False \n",
    "  model.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "  return model\n",
    "feature_loss = build_feature_loss(hr_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6wF4i0XbWxrn"
   },
   "source": [
    "build and compile the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yioy3rrNWwge"
   },
   "outputs": [],
   "source": [
    "def build_discriminator(input_size):\n",
    "  # Number of filters in the first layer of G and D\n",
    "  gf = 64\n",
    "  df = 64\n",
    "  def d_block(layer_input, filters, strides=1, bn=True):\n",
    "    \"\"\"Discriminator layer\"\"\"\n",
    "    d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    if bn:\n",
    "        d = BatchNormalization(momentum=0.8)(d)\n",
    "    return d\n",
    "\n",
    "  # Input img\n",
    "  d0 = Input(shape=input_size)\n",
    "\n",
    "  d1 = d_block(d0, df, bn=False)\n",
    "  d2 = d_block(d1, df, strides=2)\n",
    "  d3 = d_block(d2, df*2)\n",
    "  d4 = d_block(d3, df*2, strides=2)\n",
    "  d5 = d_block(d4, df*4)\n",
    "  d6 = d_block(d5, df*4, strides=2)\n",
    "  d7 = d_block(d6, df*8)\n",
    "  d8 = d_block(d7, df*8, strides=2)\n",
    "\n",
    "  d9 = Dense(df*16)(d8)\n",
    "  d10 = LeakyReLU(alpha=0.2)(d9)\n",
    "  validity = Dense(1, activation='sigmoid')(d10)\n",
    "\n",
    "  model = Model(d0, validity)\n",
    "  model.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "discriminator = build_discriminator(input_size=hr_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mfdNrMciXgu4"
   },
   "source": [
    "Build the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "a2IkeOr68P_L",
    "outputId": "abf8f15e-9e34-42b6-fef1-fbae41d6b440"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    }
   ],
   "source": [
    "def unet(pretrained_weights = None, input_size = (256, 256, 3)):\n",
    "  inputs = Input(input_size)\n",
    "  conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "  conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "  conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "  conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "  conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "  conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "  conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "  conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "  drop4 = Dropout(0.5)(conv4)\n",
    "  pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "  conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "  conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "  drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "  up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "  merge6 = concatenate([drop4,up6], axis = 3)\n",
    "  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "  up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "  merge7 = concatenate([conv3,up7], axis = 3)\n",
    "  conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "  conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "  up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "  merge8 = concatenate([conv2,up8], axis = 3)\n",
    "  conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "  conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "  up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "  merge9 = concatenate([conv1,up9], axis = 3)\n",
    "  conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "  conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "  conv9 = Conv2D(3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "  conv10 = Conv2D(3, 1, activation = 'tanh')(conv9)\n",
    "\n",
    "  model = Model(input = inputs, output = conv10)\n",
    "  \n",
    "  #model.summary()\n",
    "\n",
    "  if(pretrained_weights):\n",
    "    model.load_weights(pretrained_weights)\n",
    "  model.compile(optimizer = Adam(lr = 1e-4), loss = 'mse', metrics = ['accuracy'])\n",
    "  return model\n",
    "generator = unet(input_size=lr_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HiNe68yKsre-"
   },
   "outputs": [],
   "source": [
    "def build_gan(input_size):\n",
    "  # High res. and low res. images\n",
    "  img_lr = Input(shape=lr_shape)\n",
    "  # generate high res. version from low res.\n",
    "  fake_hr = generator(img_lr)\n",
    "  # extract image features of the generated img\n",
    "  fake_features = feature_loss(fake_hr)\n",
    "  # for the combined model we will only train the generator\n",
    "  discriminator.trainable = False\n",
    "  # Discriminator determines validity of generated high res. images\n",
    "  validity = discriminator(fake_hr)\n",
    "  combined = Model([img_lr], [validity, fake_features])\n",
    "  combined.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1e-3, 1], optimizer=optimizer)\n",
    "  return combined\n",
    "gan = build_gan(lr_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RcsHlVoCbj2N"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "KRrhIe8Dbm7e",
    "outputId": "b69f3953-cd82-4f30-d7cd-b39693a4a02c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 time: 0:00:01.630639\n",
      "1 time: 0:00:04.039198\n",
      "2 time: 0:00:05.595058\n",
      "3 time: 0:00:07.168828\n",
      "4 time: 0:00:08.724667\n",
      "5 time: 0:00:10.254598\n",
      "6 time: 0:00:11.792461\n",
      "7 time: 0:00:13.338349\n",
      "8 time: 0:00:14.862251\n",
      "9 time: 0:00:16.386204\n",
      "10 time: 0:00:17.919142\n",
      "11 time: 0:00:19.434062\n",
      "12 time: 0:00:20.962977\n",
      "13 time: 0:00:22.493879\n",
      "14 time: 0:00:24.006833\n",
      "15 time: 0:00:25.518816\n",
      "16 time: 0:00:27.046702\n",
      "17 time: 0:00:28.567656\n",
      "18 time: 0:00:30.083580\n",
      "19 time: 0:00:31.604512\n",
      "20 time: 0:00:33.134420\n",
      "21 time: 0:00:34.665325\n",
      "22 time: 0:00:36.189277\n",
      "23 time: 0:00:37.715209\n",
      "24 time: 0:00:39.249084\n",
      "25 time: 0:00:40.767024\n",
      "26 time: 0:00:42.285962\n",
      "27 time: 0:00:43.800932\n",
      "28 time: 0:00:45.329821\n",
      "29 time: 0:00:46.866737\n",
      "30 time: 0:00:48.394646\n",
      "31 time: 0:00:49.929519\n",
      "32 time: 0:00:51.454442\n",
      "33 time: 0:00:52.978369\n",
      "34 time: 0:00:54.498300\n",
      "35 time: 0:00:56.025216\n",
      "36 time: 0:00:57.550163\n",
      "37 time: 0:00:59.073065\n",
      "38 time: 0:01:00.603970\n",
      "39 time: 0:01:02.137889\n",
      "40 time: 0:01:03.660795\n",
      "41 time: 0:01:05.187739\n",
      "42 time: 0:01:06.721608\n",
      "43 time: 0:01:08.256503\n",
      "44 time: 0:01:09.786446\n",
      "45 time: 0:01:11.314358\n",
      "46 time: 0:01:12.840302\n",
      "47 time: 0:01:14.367222\n",
      "48 time: 0:01:15.901126\n",
      "49 time: 0:01:17.430052\n",
      "50 time: 0:01:18.962001\n",
      "51 time: 0:01:21.879233\n",
      "52 time: 0:01:23.415189\n",
      "53 time: 0:01:24.946092\n",
      "54 time: 0:01:26.486973\n",
      "55 time: 0:01:28.023843\n",
      "56 time: 0:01:29.557730\n",
      "57 time: 0:01:31.089688\n",
      "58 time: 0:01:32.616633\n",
      "59 time: 0:01:34.147509\n",
      "60 time: 0:01:35.680414\n",
      "61 time: 0:01:37.210341\n",
      "62 time: 0:01:38.738260\n",
      "63 time: 0:01:40.279153\n",
      "64 time: 0:01:41.810060\n",
      "65 time: 0:01:43.344983\n",
      "66 time: 0:01:44.889822\n",
      "67 time: 0:01:46.423807\n",
      "68 time: 0:01:47.958676\n",
      "69 time: 0:01:49.497560\n",
      "70 time: 0:01:51.028493\n",
      "71 time: 0:01:52.571362\n",
      "72 time: 0:01:54.103272\n",
      "73 time: 0:01:55.634193\n",
      "74 time: 0:01:57.175082\n",
      "75 time: 0:01:58.705988\n",
      "76 time: 0:02:00.239885\n",
      "77 time: 0:02:01.769815\n",
      "78 time: 0:02:03.304688\n",
      "79 time: 0:02:04.842576\n",
      "80 time: 0:02:06.379465\n",
      "81 time: 0:02:07.917352\n",
      "82 time: 0:02:09.443294\n",
      "83 time: 0:02:10.978172\n",
      "84 time: 0:02:12.519044\n",
      "85 time: 0:02:14.052942\n",
      "86 time: 0:02:15.577864\n",
      "87 time: 0:02:17.121757\n",
      "88 time: 0:02:18.655654\n",
      "89 time: 0:02:20.187556\n",
      "90 time: 0:02:21.719437\n",
      "91 time: 0:02:23.250372\n",
      "92 time: 0:02:24.786235\n",
      "93 time: 0:02:26.318139\n",
      "94 time: 0:02:27.860014\n",
      "95 time: 0:02:29.388925\n",
      "96 time: 0:02:30.922822\n",
      "97 time: 0:02:32.459740\n",
      "98 time: 0:02:33.990642\n",
      "99 time: 0:02:35.522575\n",
      "100 time: 0:02:37.061432\n",
      "101 time: 0:02:39.424113\n",
      "102 time: 0:02:40.954043\n",
      "103 time: 0:02:42.491918\n",
      "104 time: 0:02:44.030848\n",
      "105 time: 0:02:45.586702\n",
      "106 time: 0:02:47.147500\n",
      "107 time: 0:02:48.688421\n",
      "108 time: 0:02:50.230299\n",
      "109 time: 0:02:51.757216\n",
      "110 time: 0:02:53.294127\n",
      "111 time: 0:02:54.838999\n",
      "112 time: 0:02:56.375864\n",
      "113 time: 0:02:57.913749\n",
      "114 time: 0:02:59.446649\n",
      "115 time: 0:03:00.982564\n",
      "116 time: 0:03:02.524443\n",
      "117 time: 0:03:04.056321\n",
      "118 time: 0:03:05.594208\n",
      "119 time: 0:03:07.129104\n",
      "120 time: 0:03:08.665017\n",
      "121 time: 0:03:10.198892\n",
      "122 time: 0:03:11.726806\n",
      "123 time: 0:03:13.262728\n",
      "124 time: 0:03:14.789614\n",
      "125 time: 0:03:16.328498\n",
      "126 time: 0:03:17.861427\n",
      "127 time: 0:03:19.388315\n",
      "128 time: 0:03:20.922240\n",
      "129 time: 0:03:22.451140\n",
      "130 time: 0:03:23.983026\n",
      "131 time: 0:03:25.514957\n",
      "132 time: 0:03:27.052817\n",
      "133 time: 0:03:28.586742\n",
      "134 time: 0:03:30.111636\n",
      "135 time: 0:03:31.644596\n",
      "136 time: 0:03:33.182447\n",
      "137 time: 0:03:34.712356\n",
      "138 time: 0:03:36.243261\n",
      "139 time: 0:03:37.770178\n",
      "140 time: 0:03:39.297093\n",
      "141 time: 0:03:40.825007\n",
      "142 time: 0:03:42.357908\n",
      "143 time: 0:03:43.890807\n",
      "144 time: 0:03:45.417747\n",
      "145 time: 0:03:46.961595\n",
      "146 time: 0:03:48.501477\n",
      "147 time: 0:03:50.039390\n",
      "148 time: 0:03:51.574281\n",
      "149 time: 0:03:53.113165\n",
      "150 time: 0:03:54.648037\n",
      "151 time: 0:03:57.004768\n",
      "152 time: 0:03:58.537709\n",
      "153 time: 0:04:00.076594\n",
      "154 time: 0:04:01.605504\n",
      "155 time: 0:04:03.142394\n",
      "156 time: 0:04:04.680281\n",
      "157 time: 0:04:06.208218\n",
      "158 time: 0:04:07.745084\n",
      "159 time: 0:04:09.277015\n",
      "160 time: 0:04:10.805925\n",
      "161 time: 0:04:12.347775\n",
      "162 time: 0:04:13.881672\n",
      "163 time: 0:04:15.440502\n",
      "164 time: 0:04:16.992374\n",
      "165 time: 0:04:18.527248\n",
      "166 time: 0:04:20.068157\n",
      "167 time: 0:04:21.601057\n",
      "168 time: 0:04:23.136950\n",
      "169 time: 0:04:24.662868\n",
      "170 time: 0:04:26.192776\n",
      "171 time: 0:04:27.721719\n",
      "172 time: 0:04:29.257634\n",
      "173 time: 0:04:30.799487\n",
      "174 time: 0:04:32.322442\n",
      "175 time: 0:04:33.856312\n",
      "176 time: 0:04:35.389240\n",
      "177 time: 0:04:36.928119\n",
      "178 time: 0:04:38.469972\n",
      "179 time: 0:04:40.007859\n",
      "180 time: 0:04:41.541766\n",
      "181 time: 0:04:43.075683\n",
      "182 time: 0:04:44.632494\n",
      "183 time: 0:04:46.166388\n",
      "184 time: 0:04:47.720261\n",
      "185 time: 0:04:49.260137\n",
      "186 time: 0:04:50.801017\n",
      "187 time: 0:04:52.334890\n",
      "188 time: 0:04:53.865796\n",
      "189 time: 0:04:55.402685\n",
      "190 time: 0:04:56.933591\n",
      "191 time: 0:04:58.467489\n",
      "192 time: 0:05:00.002410\n",
      "193 time: 0:05:01.538284\n",
      "194 time: 0:05:03.073171\n",
      "195 time: 0:05:04.606093\n",
      "196 time: 0:05:06.144989\n",
      "197 time: 0:05:07.683861\n",
      "198 time: 0:05:09.214780\n",
      "199 time: 0:05:10.754661\n",
      "200 time: 0:05:12.301545\n",
      "201 time: 0:05:14.646273\n",
      "202 time: 0:05:16.181194\n",
      "203 time: 0:05:17.710108\n",
      "204 time: 0:05:19.234026\n",
      "205 time: 0:05:20.769924\n",
      "206 time: 0:05:22.299804\n",
      "207 time: 0:05:23.825745\n",
      "208 time: 0:05:25.359621\n",
      "209 time: 0:05:26.886537\n",
      "210 time: 0:05:28.411481\n",
      "211 time: 0:05:29.935410\n",
      "212 time: 0:05:31.465313\n",
      "213 time: 0:05:32.995198\n",
      "214 time: 0:05:34.518125\n",
      "215 time: 0:05:36.058030\n",
      "216 time: 0:05:37.593926\n",
      "217 time: 0:05:39.121844\n",
      "218 time: 0:05:40.648729\n",
      "219 time: 0:05:42.179657\n",
      "220 time: 0:05:43.695580\n",
      "221 time: 0:05:45.227483\n",
      "222 time: 0:05:46.754423\n",
      "223 time: 0:05:48.281315\n",
      "224 time: 0:05:49.809256\n",
      "225 time: 0:05:51.350135\n",
      "226 time: 0:05:52.884005\n",
      "227 time: 0:05:54.413927\n",
      "228 time: 0:05:55.950851\n",
      "229 time: 0:05:57.481747\n",
      "230 time: 0:05:59.012653\n",
      "231 time: 0:06:00.545576\n",
      "232 time: 0:06:02.077481\n",
      "233 time: 0:06:03.603375\n",
      "234 time: 0:06:05.146271\n",
      "235 time: 0:06:06.683138\n",
      "236 time: 0:06:08.215042\n",
      "237 time: 0:06:09.753925\n",
      "238 time: 0:06:11.282858\n",
      "239 time: 0:06:12.819725\n",
      "240 time: 0:06:14.342676\n",
      "241 time: 0:06:15.878556\n",
      "242 time: 0:06:17.410474\n",
      "243 time: 0:06:18.938388\n",
      "244 time: 0:06:20.457340\n",
      "245 time: 0:06:21.992220\n",
      "246 time: 0:06:23.517164\n",
      "247 time: 0:06:25.055057\n",
      "248 time: 0:06:26.575977\n",
      "249 time: 0:06:28.118835\n",
      "250 time: 0:06:29.649740\n",
      "251 time: 0:06:32.001450\n",
      "252 time: 0:06:33.534373\n",
      "253 time: 0:06:35.074239\n",
      "254 time: 0:06:36.598156\n",
      "255 time: 0:06:38.130062\n",
      "256 time: 0:06:39.656004\n",
      "257 time: 0:06:41.183905\n",
      "258 time: 0:06:42.712812\n",
      "259 time: 0:06:44.238721\n",
      "260 time: 0:06:45.789604\n",
      "261 time: 0:06:47.332447\n",
      "262 time: 0:06:48.872328\n",
      "263 time: 0:06:50.411217\n",
      "264 time: 0:06:51.945137\n",
      "265 time: 0:06:53.483994\n",
      "266 time: 0:06:55.020905\n",
      "267 time: 0:06:56.552832\n",
      "268 time: 0:06:58.092691\n",
      "269 time: 0:06:59.631599\n",
      "270 time: 0:07:01.167495\n",
      "271 time: 0:07:02.691413\n",
      "272 time: 0:07:04.221299\n",
      "273 time: 0:07:05.761179\n",
      "274 time: 0:07:07.292114\n",
      "275 time: 0:07:08.826007\n",
      "276 time: 0:07:10.363870\n",
      "277 time: 0:07:11.884810\n",
      "278 time: 0:07:13.413713\n",
      "279 time: 0:07:14.952624\n",
      "280 time: 0:07:16.479536\n",
      "281 time: 0:07:18.024382\n",
      "282 time: 0:07:19.566285\n",
      "283 time: 0:07:21.097175\n",
      "284 time: 0:07:22.623082\n",
      "285 time: 0:07:24.148073\n",
      "286 time: 0:07:25.686955\n",
      "287 time: 0:07:27.219879\n",
      "288 time: 0:07:28.748793\n",
      "289 time: 0:07:30.278704\n",
      "290 time: 0:07:31.817559\n",
      "291 time: 0:07:33.343500\n",
      "292 time: 0:07:34.868429\n",
      "293 time: 0:07:36.392354\n",
      "294 time: 0:07:37.925224\n",
      "295 time: 0:07:39.447180\n",
      "296 time: 0:07:40.969082\n",
      "297 time: 0:07:42.502980\n",
      "298 time: 0:07:44.037898\n",
      "299 time: 0:07:45.566813\n",
      "300 time: 0:07:47.095724\n",
      "301 time: 0:07:49.453420\n",
      "302 time: 0:07:50.982302\n",
      "303 time: 0:07:52.518247\n",
      "304 time: 0:07:54.057131\n",
      "305 time: 0:07:55.591029\n",
      "306 time: 0:07:57.138890\n",
      "307 time: 0:07:58.673807\n",
      "308 time: 0:08:00.201729\n",
      "309 time: 0:08:01.730631\n",
      "310 time: 0:08:03.269516\n",
      "311 time: 0:08:04.795434\n",
      "312 time: 0:08:06.329309\n",
      "313 time: 0:08:07.854231\n",
      "314 time: 0:08:09.383172\n",
      "315 time: 0:08:10.920050\n",
      "316 time: 0:08:12.449939\n",
      "317 time: 0:08:13.986856\n",
      "318 time: 0:08:15.518754\n",
      "319 time: 0:08:17.048640\n",
      "320 time: 0:08:18.578548\n",
      "321 time: 0:08:20.115464\n",
      "322 time: 0:08:21.655319\n",
      "323 time: 0:08:23.195201\n",
      "324 time: 0:08:24.735082\n",
      "325 time: 0:08:26.264991\n",
      "326 time: 0:08:27.797899\n",
      "327 time: 0:08:29.328823\n",
      "328 time: 0:08:30.858704\n",
      "329 time: 0:08:32.397602\n",
      "330 time: 0:08:33.932490\n",
      "331 time: 0:08:35.467403\n",
      "332 time: 0:08:37.001298\n",
      "333 time: 0:08:38.553125\n",
      "334 time: 0:08:40.077077\n",
      "335 time: 0:08:41.608952\n",
      "336 time: 0:08:43.147859\n",
      "337 time: 0:08:44.691715\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_18 to have 4 dimensions, but got array with shape (1, 512, 512)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-be36a2f79d16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m   \u001b[1;31m# Train the discriminators (original images = real / generated = Fake)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m   \u001b[0md_loss_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_hr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m   \u001b[0md_loss_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_hr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m   \u001b[0md_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_loss_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1506\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1507\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1508\u001b[1;33m             class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1509\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_18 to have 4 dimensions, but got array with shape (1, 512, 512)"
     ]
    }
   ],
   "source": [
    "#! rm -rf ./samples\n",
    "epochs=30000\n",
    "batch_size=1\n",
    "sample_interval=50\n",
    "start_time = datetime.datetime.now()\n",
    "for epoch in range(epochs+1):\n",
    "  # calculate output shape of D (PatchGAN)\n",
    "  patch = int(width / 2**4)\n",
    "  disc_patch = (patch, patch, 1)\n",
    "  # ----------------------\n",
    "  #  Train Discriminator\n",
    "  # ----------------------\n",
    "\n",
    "  # Sample images and their conditioning counterparts\n",
    "  imgs_hr, imgs_lr = data_loader.load_data(batch_size)\n",
    "\n",
    "  # From low res. image generate high res. version\n",
    "  fake_hr = generator.predict(imgs_lr)\n",
    "\n",
    "  valid = np.ones((batch_size,) + disc_patch)\n",
    "  fake = np.zeros((batch_size,) + disc_patch)\n",
    "\n",
    "  # Train the discriminators (original images = real / generated = Fake)\n",
    "  d_loss_real = discriminator.train_on_batch(imgs_hr, valid)\n",
    "  d_loss_fake = discriminator.train_on_batch(fake_hr, fake)\n",
    "  d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "  # ------------------\n",
    "  #  Train Generator\n",
    "  # ------------------\n",
    "\n",
    "  # Sample images and their conditioning counterparts\n",
    "  imgs_hr, imgs_lr = data_loader.load_data(batch_size)\n",
    "\n",
    "  # The generators want the discriminators to label the generated images as real\n",
    "  valid = np.ones((batch_size,) + disc_patch)\n",
    "\n",
    "  # Extract ground truth image features using pre-trained VGG19 model\n",
    "  image_features = feature_loss.predict(imgs_hr)\n",
    "\n",
    "  # Train the generators\n",
    "  g_loss = gan.train_on_batch([imgs_lr], [valid, image_features])\n",
    "\n",
    "  elapsed_time = datetime.datetime.now() - start_time\n",
    "  # Plot the progress\n",
    "  print (\"%d time: %s\" % (epoch, elapsed_time))\n",
    "\n",
    "  # If at save interval => save generated image samples\n",
    "  if epoch % sample_interval == 0:\n",
    "      sample_images(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x202bc7fbcc8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l576mANkDFzK"
   },
   "outputs": [],
   "source": [
    "save_generator = keras.Sequential([generator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvvPaO-wFC9T"
   },
   "outputs": [],
   "source": [
    "save_generator.add(Lambda(lambda x: (x + 1) * 127.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_DQC9aKuZ9-"
   },
   "source": [
    "## Convert to CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gCiDYRwwvczg"
   },
   "outputs": [],
   "source": [
    "save_generator.save('generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting coremltools==3.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/bf/ae44737a06c21e64b6e950bc6da4652c3127656daeec95994210c23826c4/coremltools-3.2-cp37-none-macosx_10_15_intel.whl (4.0MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0MB 686kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /opt/anaconda3/lib/python3.7/site-packages (from coremltools==3.2) (1.17.2)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /opt/anaconda3/lib/python3.7/site-packages (from coremltools==3.2) (3.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/anaconda3/lib/python3.7/site-packages (from coremltools==3.2) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from protobuf>=3.1.0->coremltools==3.2) (41.4.0)\n",
      "Installing collected packages: coremltools\n",
      "  Found existing installation: coremltools 3.4\n",
      "    Uninstalling coremltools-3.4:\n",
      "      Successfully uninstalled coremltools-3.4\n",
      "Successfully installed coremltools-3.2\n"
     ]
    }
   ],
   "source": [
    "! pip install coremltools==3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wrNl1_mXufuw",
    "outputId": "d2a684c5-a5f1-4217-f595-13dc84d6db2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.2.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 158kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.17.2)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.1.0)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (5.1.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.0.8)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.2.4\n",
      "Collecting tensorflow==1.14.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/11/037887c5cbac5af3124050fb6348e67caa038734cc9673b11c31c8939072/tensorflow-1.14.0-cp37-cp37m-macosx_10_11_x86_64.whl (105.8MB)\n",
      "\u001b[K     |████████████████████████████████| 105.8MB 263kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0 (from tensorflow==1.14.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 10.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.17.2)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow==1.14.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "\u001b[K     |████████████████████████████████| 491kB 2.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.33.6)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (3.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.9.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.7.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.2.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.11.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.23.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (41.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/anaconda3/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.16.0)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.9.0)\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
      "  Found existing installation: tensorboard 2.0.0\n",
      "    Uninstalling tensorboard-2.0.0:\n",
      "      Successfully uninstalled tensorboard-2.0.0\n",
      "  Found existing installation: tensorflow-estimator 2.0.0\n",
      "    Uninstalling tensorflow-estimator-2.0.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.0.0\n",
      "  Found existing installation: tensorflow 2.0.0\n",
      "    Uninstalling tensorflow-2.0.0:\n",
      "      Successfully uninstalled tensorflow-2.0.0\n",
      "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
     ]
    }
   ],
   "source": [
    "! pip install keras==2.2.4\n",
    "! pip install tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "4cqRZufbFuD8",
    "outputId": "80289a90-2ca4-449b-d0ad-cbf1fa998e96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "from coremltools.proto import NeuralNetwork_pb2\n",
    "\n",
    "def convert_lambda(layer):\n",
    "    params = NeuralNetwork_pb2.CustomLayerParams()\n",
    "\n",
    "    # The name of the Swift or Obj-C class that implements this layer.\n",
    "    params.className = \"Lambda\"\n",
    "\n",
    "    # The desciption is shown in Xcode's mlmodel viewer.\n",
    "    params.description = \"Post process\"\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.4 (default, Aug 13 2019, 15:17:50) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)] :: Anaconda, Inc. on darwin\n",
      "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
      ">>> "
     ]
    }
   ],
   "source": [
    "! python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xKfEzd8KdGYO",
    "outputId": "fe393777-b751-4722-9481-8b88e54ca1ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "/opt/anaconda3/lib/python3.7/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : model_15_input, <keras.engine.input_layer.InputLayer object at 0x1a33d54590>\n",
      "1 : model_15_conv2d_105, <keras.layers.convolutional.Conv2D object at 0x1a33d54a50>\n",
      "2 : model_15_conv2d_105__activation__, <keras.layers.core.Activation object at 0x1a343b81d0>\n",
      "3 : model_15_conv2d_106, <keras.layers.convolutional.Conv2D object at 0x1a33d54b10>\n",
      "4 : model_15_conv2d_106__activation__, <keras.layers.core.Activation object at 0x1a33d3e050>\n",
      "5 : model_15_max_pooling2d_13, <keras.layers.pooling.MaxPooling2D object at 0x1a33d54d90>\n",
      "6 : model_15_conv2d_107, <keras.layers.convolutional.Conv2D object at 0x1a33d54bd0>\n",
      "7 : model_15_conv2d_107__activation__, <keras.layers.core.Activation object at 0x1a33d3e350>\n",
      "8 : model_15_conv2d_108, <keras.layers.convolutional.Conv2D object at 0x1a33d8c150>\n",
      "9 : model_15_conv2d_108__activation__, <keras.layers.core.Activation object at 0x1a33d3e290>\n",
      "10 : model_15_max_pooling2d_14, <keras.layers.pooling.MaxPooling2D object at 0x1a33d8c350>\n",
      "11 : model_15_conv2d_109, <keras.layers.convolutional.Conv2D object at 0x1a33d8c550>\n",
      "12 : model_15_conv2d_109__activation__, <keras.layers.core.Activation object at 0x1a33d3e250>\n",
      "13 : model_15_conv2d_110, <keras.layers.convolutional.Conv2D object at 0x1a33d8c650>\n",
      "14 : model_15_conv2d_110__activation__, <keras.layers.core.Activation object at 0x1a33d3e1d0>\n",
      "15 : model_15_max_pooling2d_15, <keras.layers.pooling.MaxPooling2D object at 0x1a33d8c850>\n",
      "16 : model_15_conv2d_111, <keras.layers.convolutional.Conv2D object at 0x1a33d8ca50>\n",
      "17 : model_15_conv2d_111__activation__, <keras.layers.core.Activation object at 0x1a33d3e0d0>\n",
      "18 : model_15_conv2d_112, <keras.layers.convolutional.Conv2D object at 0x1a33d8cb50>\n",
      "19 : model_15_conv2d_112__activation__, <keras.layers.core.Activation object at 0x1a33d3e490>\n",
      "20 : model_15_max_pooling2d_16, <keras.layers.pooling.MaxPooling2D object at 0x1a33d54a90>\n",
      "21 : model_15_conv2d_113, <keras.layers.convolutional.Conv2D object at 0x1a33d8cf90>\n",
      "22 : model_15_conv2d_113__activation__, <keras.layers.core.Activation object at 0x1a33d3e3d0>\n",
      "23 : model_15_conv2d_114, <keras.layers.convolutional.Conv2D object at 0x1a33d930d0>\n",
      "24 : model_15_conv2d_114__activation__, <keras.layers.core.Activation object at 0x1a33d3e750>\n",
      "25 : model_15_up_sampling2d_13, <keras.layers.convolutional.UpSampling2D object at 0x1a33d93490>\n",
      "26 : model_15_conv2d_115, <keras.layers.convolutional.Conv2D object at 0x1a33d93450>\n",
      "27 : model_15_conv2d_115__activation__, <keras.layers.core.Activation object at 0x1a33d3e6d0>\n",
      "28 : model_15_concatenate_13, <keras.layers.merge.Concatenate object at 0x1a33d93590>\n",
      "29 : model_15_conv2d_116, <keras.layers.convolutional.Conv2D object at 0x1a33d93750>\n",
      "30 : model_15_conv2d_116__activation__, <keras.layers.core.Activation object at 0x1a33d3e650>\n",
      "31 : model_15_conv2d_117, <keras.layers.convolutional.Conv2D object at 0x1a33d937d0>\n",
      "32 : model_15_conv2d_117__activation__, <keras.layers.core.Activation object at 0x1a33d3e550>\n",
      "33 : model_15_up_sampling2d_14, <keras.layers.convolutional.UpSampling2D object at 0x1a33d939d0>\n",
      "34 : model_15_conv2d_118, <keras.layers.convolutional.Conv2D object at 0x1a33d93710>\n",
      "35 : model_15_conv2d_118__activation__, <keras.layers.core.Activation object at 0x1a33d3ea90>\n",
      "36 : model_15_concatenate_14, <keras.layers.merge.Concatenate object at 0x1a33d93c50>\n",
      "37 : model_15_conv2d_119, <keras.layers.convolutional.Conv2D object at 0x1a33d93e10>\n",
      "38 : model_15_conv2d_119__activation__, <keras.layers.core.Activation object at 0x1a33d3ea10>\n",
      "39 : model_15_conv2d_120, <keras.layers.convolutional.Conv2D object at 0x1a33d93dd0>\n",
      "40 : model_15_conv2d_120__activation__, <keras.layers.core.Activation object at 0x1a33d3e990>\n",
      "41 : model_15_up_sampling2d_15, <keras.layers.convolutional.UpSampling2D object at 0x1a33d9a0d0>\n",
      "42 : model_15_conv2d_121, <keras.layers.convolutional.Conv2D object at 0x1a33d9a090>\n",
      "43 : model_15_conv2d_121__activation__, <keras.layers.core.Activation object at 0x1a33d3e910>\n",
      "44 : model_15_concatenate_15, <keras.layers.merge.Concatenate object at 0x1a33d9a350>\n",
      "45 : model_15_conv2d_122, <keras.layers.convolutional.Conv2D object at 0x1a33d9a510>\n",
      "46 : model_15_conv2d_122__activation__, <keras.layers.core.Activation object at 0x1a33d3e810>\n",
      "47 : model_15_conv2d_123, <keras.layers.convolutional.Conv2D object at 0x1a33d9a590>\n",
      "48 : model_15_conv2d_123__activation__, <keras.layers.core.Activation object at 0x1a33d3eb90>\n",
      "49 : model_15_up_sampling2d_16, <keras.layers.convolutional.UpSampling2D object at 0x1a33d9a790>\n",
      "50 : model_15_conv2d_124, <keras.layers.convolutional.Conv2D object at 0x1a33d9a4d0>\n",
      "51 : model_15_conv2d_124__activation__, <keras.layers.core.Activation object at 0x1a33d3eb10>\n",
      "52 : model_15_concatenate_16, <keras.layers.merge.Concatenate object at 0x1a33d9aa10>\n",
      "53 : model_15_conv2d_125, <keras.layers.convolutional.Conv2D object at 0x1a33d9abd0>\n",
      "54 : model_15_conv2d_125__activation__, <keras.layers.core.Activation object at 0x1a33d3ee50>\n",
      "55 : model_15_conv2d_126, <keras.layers.convolutional.Conv2D object at 0x1a33d9ac50>\n",
      "56 : model_15_conv2d_126__activation__, <keras.layers.core.Activation object at 0x1a33d3edd0>\n",
      "57 : model_15_conv2d_127, <keras.layers.convolutional.Conv2D object at 0x1a33d9ae50>\n",
      "58 : model_15_conv2d_127__activation__, <keras.layers.core.Activation object at 0x1a33d3ed50>\n",
      "59 : model_15_conv2d_128, <keras.layers.convolutional.Conv2D object at 0x1a33da1210>\n",
      "60 : model_15_conv2d_128__activation__, <keras.layers.core.Activation object at 0x1a33d3ecd0>\n",
      "61 : lambda_1, <keras.layers.core.Lambda object at 0x1a34592350>\n",
      "\n",
      "\n",
      "Recommendation: This model has at least one multiarray input/output of type double.\n",
      "For large sized arrays, multiarrays of type float32 are more efficient.\n",
      "In future, float input/output multiarrays will be produced by default by the converter.\n",
      "Please use, either the flag 'use_float_arraytype' during the call to convert or\n",
      "the utility 'coremltools.utils.convert_double_to_float_multiarray_type(spec)', post-conversion.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/coremltools/models/model.py:111: RuntimeWarning: You will not be able to run predict() on this Core ML model. Underlying exception message was: Error compiling model: \"compiler error:  Error creating Core ML custom layer implementation from factory for layer \"Lambda\".\".\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import coremltools\n",
    "coreml_model = coremltools.converters.keras.convert('generator.h5', input_names='input', output_names='output', image_input_names='input', add_custom_layers=True, image_scale=1/127.5, gray_bias=-1, custom_conversion_functions={ \"Lambda\": convert_lambda })\n",
    "\n",
    "# Saving the Core ML model to a file.\n",
    "coreml_model.save('colorizer.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lvRkAU67GlYH"
   },
   "outputs": [],
   "source": [
    "import coremltools\n",
    "import coremltools.proto.FeatureTypes_pb2 as ft \n",
    "\n",
    "spec = coremltools.utils.load_spec(\"colorizer.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OGM09r11GoUF"
   },
   "outputs": [],
   "source": [
    "output = spec.description.output[0]\n",
    "width = 512\n",
    "import coremltools.proto.FeatureTypes_pb2 as ft\n",
    "output.type.imageType.colorSpace = ft.ImageFeatureType.RGB\n",
    "output.type.imageType.height = width\n",
    "output.type.imageType.width = width\n",
    "\n",
    "coremltools.utils.save_spec(spec, \"Colorizer2.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WfV0PXb1Hohb",
    "outputId": "7f5cde37-668d-45b5-95c2-bb682c549f72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling Keras-2.2.4:\n",
      "  Would remove:\n",
      "    /usr/local/lib/python3.6/dist-packages/Keras-2.2.4.dist-info/*\n",
      "    /usr/local/lib/python3.6/dist-packages/docs/*\n",
      "    /usr/local/lib/python3.6/dist-packages/keras/*\n",
      "  Would not remove (might be manually added):\n",
      "    /usr/local/lib/python3.6/dist-packages/docs/md_autogen.py\n",
      "    /usr/local/lib/python3.6/dist-packages/docs/update_docs.py\n",
      "Proceed (y/n)? y\n",
      "  Successfully uninstalled Keras-2.2.4\n",
      "Uninstalling tensorflow-1.14.0:\n",
      "  Would remove:\n",
      "    /usr/local/bin/freeze_graph\n",
      "    /usr/local/bin/saved_model_cli\n",
      "    /usr/local/bin/tensorboard\n",
      "    /usr/local/bin/tf_upgrade_v2\n",
      "    /usr/local/bin/tflite_convert\n",
      "    /usr/local/bin/toco\n",
      "    /usr/local/bin/toco_from_protos\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow-1.14.0.dist-info/*\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
      "Proceed (y/n)? y\n",
      "  Successfully uninstalled tensorflow-1.14.0\n",
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/be/679ce5254a8c8d07470efb4a4c00345fae91f766e64f1c2aece8796d7218/tensorflow-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n",
      "\u001b[K     |████████████████████████████████| 516.2MB 34kB/s \n",
      "\u001b[?25hCollecting tensorboard<2.3.0,>=2.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/fd/4f3ca1516cbb3713259ef229abd9314bba0077ef6070285dde0dd1ed21b2/tensorboard-2.2.1-py3-none-any.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 35.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
      "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n",
      "\u001b[K     |████████████████████████████████| 460kB 57.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.29.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (46.3.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
      "\u001b[31mERROR: fancyimpute 0.4.3 requires keras>=2.0.0, which is not installed.\u001b[0m\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
      "  Found existing installation: tensorboard 1.14.0\n",
      "    Uninstalling tensorboard-1.14.0:\n",
      "      Successfully uninstalled tensorboard-1.14.0\n",
      "  Found existing installation: tensorflow-estimator 1.14.0\n",
      "    Uninstalling tensorflow-estimator-1.14.0:\n",
      "      Successfully uninstalled tensorflow-estimator-1.14.0\n",
      "Successfully installed tensorboard-2.2.1 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "tensorboard",
         "tensorflow",
         "tensorflow_estimator"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K     |████████████████████████████████| 378kB 2.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.3.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "keras"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "! pip uninstall keras\n",
    "! pip uninstall tensorflow\n",
    "! pip install tensorflow\n",
    "! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y77D0L9BX7pw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "keras colorizer",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
